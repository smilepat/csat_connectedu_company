# app/services/llm_client.py
from __future__ import annotations
import json, re, time, os, traceback
from typing import Any, Dict, Callable, Optional

from app.core.openai_config import chat_completion, DEFAULT_TEMPERATURE, DEFAULT_MAX_TOKENS

DEFAULT_TIMEOUT_S = 30

# ê°€ì¥ ë§ˆì§€ë§‰ì— ë‹«íˆëŠ” JSON ê°ì²´ í›„ë³´
_JSON_BLOCK_RE = re.compile(r"\{[\s\S]*\}$")
# ``` ë˜ëŠ” ```json íœìŠ¤ ì œê±°
_FENCE_RE = re.compile(r"^```(?:json)?\s*|\s*```$", re.I | re.M)

# ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ ë§µ (âš ï¸ íŒŒì‹± "í›„"ì—ë§Œ ì‚¬ìš©)
_SMART_QUOTES = {
    "\u201c": '"', "\u201d": '"', "\u201e": '"', "\u201f": '"',
    "\u2018": "'", "\u2019": "'", "\u2032": "'", "\u2033": '"'
}
# íŠ¸ë ˆì¼ë§ ì½¤ë§ˆ ì œê±°( }, ] ì§ì „ )
_RE_TRAILING_COMMA = re.compile(r",\s*([}\]])")

_CIRCLED = "â‘ â‘¡â‘¢â‘£â‘¤"

DEBUG_LLM = os.getenv("DEBUG_LLM", "1").lower() in ("1", "true", "yes", "on")

CONTROL_CHARS_RE = re.compile(r'[\x00-\x08\x0B\x0C\x0E-\x1F]')


def _strip_code_fences(txt: str) -> str:
    return _FENCE_RE.sub("", txt or "").strip()


def _normalize_quotes_in_str(s: str) -> str:
    # íŒŒì‹± "í›„" ë¬¸ìì—´ í•„ë“œì—ì„œë§Œ í˜¸ì¶œ
    for k, v in _SMART_QUOTES.items():
        s = s.replace(k, v)
    return s


def strip_control_chars(s: str) -> str:
    try:
        return CONTROL_CHARS_RE.sub(' ', s or '')
    except Exception:
        return s or ''


def strip_controls_deep(obj):
    """dict/list ë‚´ ëª¨ë“  str í•„ë“œì—ì„œ ì œì–´ë¬¸ì ì œê±°"""
    if isinstance(obj, dict):
        return {k: strip_controls_deep(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [strip_controls_deep(v) for v in obj]
    if isinstance(obj, str):
        return strip_control_chars(obj)
    return obj


def normalize_quotes_deep(obj):
    """dict/list ë‚´ ëª¨ë“  str í•„ë“œì—ì„œ ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ â†’ í‘œì¤€ ë”°ì˜´í‘œ (íŒŒì‹± ì´í›„ì—ë§Œ)"""
    if isinstance(obj, dict):
        return {k: normalize_quotes_deep(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [normalize_quotes_deep(v) for v in obj]
    if isinstance(obj, str):
        return _normalize_quotes_in_str(obj)
    return obj


def _quote_bare_circled(s: str) -> str:
    """
    ë¬¸ìì—´ ë°”ê¹¥ì— ë‹¨ë…ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” â‘ ~â‘¤ë¥¼ "â‘ "ì²˜ëŸ¼ ê°ì‹¼ë‹¤.
    - JSON ë¬¸ìì—´ ë‚´ë¶€ëŠ” ê±´ë“œë¦¬ì§€ ì•Šê¸° ìœ„í•´ ê°„ë‹¨í•œ ìƒíƒœë¨¸ì‹  ì‚¬ìš©.
    """
    out = []
    in_str = False
    esc = False
    for ch in s:
        if in_str:
            out.append(ch)
            if esc:
                esc = False
            elif ch == '\\':
                esc = True
            elif ch == '"':
                in_str = False
            continue
        else:
            if ch == '"':
                in_str = True
                out.append(ch)
                continue
            if ch in _CIRCLED:
                out.append(f'"{ch}"')
            else:
                out.append(ch)
    return "".join(out)


def _extract_outer_json_block(s: str) -> str:
    """
    - ë¬¸ìì—´ì´ ê³§ë°”ë¡œ JSONì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    - ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ì— ë‚˜íƒ€ë‚œ { ... } ë¸”ë¡ì„ ì¶”ì¶œ
    """
    # ë°”ë¡œ ë¡œë“œ ê°€ëŠ¥í•œì§€ 1ì°¨ ì‹œë„
    try:
        json.loads(s)
        return s
    except Exception:
        pass
    m = _JSON_BLOCK_RE.search(s)
    if not m:
        raise ValueError("No JSON object found in model response.")
    return m.group(0)


def _preclean_jsonish(raw: str) -> str:
    """
    ëª¨ë¸ ì‘ë‹µ(JSONìŠ¤ëŸ¬ì›€)ì„ íŒŒì‹±í•˜ê¸° ì „ì— ì•ˆì „í•˜ê²Œ ì •ë¦¬:
      1) ì½”ë“œíœìŠ¤ ì œê±°
      2) (ì‚­ì œ) ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ ì •ê·œí™”  âŒ  â† íŒŒì‹± "ì „"ì—ëŠ” ê¸ˆì§€
      3) ë¬¸ìì—´ ë°”ê¹¥ì˜ â‘ ~â‘¤ ë¥¼ ê°•ì œë¡œ ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
      4) íŠ¸ë ˆì¼ë§ ì½¤ë§ˆ ì œê±°
      5) ê°€ì¥ ë°”ê¹¥ { ... } ë¸”ë¡ ì¶”ì¶œ
    """
    s = _strip_code_fences(raw)
    # âŒ s = _normalize_quotes(s)  # íŒŒì‹± ì „ì— í•˜ë©´ ë¬¸ìì—´ ë‚´ë¶€ ì¸ìš©ë¶€í˜¸ê°€ ê¹¨ì§‘ë‹ˆë‹¤.
    s = _quote_bare_circled(s)
    s = _RE_TRAILING_COMMA.sub(r"\1", s)
    s = _extract_outer_json_block(s)
    return s


def _extract_json(txt: str) -> Dict[str, Any]:
    """
    ëª¨ë¸ì´ ì„¤ëª… + JSONì„ ì„ì–´ ë³´ë‚¼ ë•Œ, ë³¸ë¬¸ì—ì„œ JSONë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ.
    ê°•í™” í¬ë§·í„°ë¥¼ í†µí•´ í”í•œ íŒŒì‹± ì‹¤íŒ¨ ìš”ì¸ì„ ì œê±°.
    """
    s = _preclean_jsonish(txt or "")
    return json.loads(s)


def _retry(fn: Callable[[], Dict[str, Any]], retries: int = 2, backoff: float = 0.8) -> Optional[Dict[str, Any]]:
    last = None
    for i in range(retries + 1):
        try:
            return fn()
        except Exception as e:
            last = e
            if DEBUG_LLM:
                # ìš”ì•½ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³ , ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ëŠ” ë§ˆì§€ë§‰ 1íšŒë§Œ ì„ íƒì ìœ¼ë¡œ
                print(f"[call_llm_json] attempt {i+1}/{retries} failed: {e}")
            if i < retries:
                time.sleep(backoff * (i + 1))
    # ğŸ”‡ ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ ê³¼ë‹¤ ì¶œë ¥ ë°©ì§€: í•„ìš” ì‹œì—ë§Œ
    if DEBUG_LLM and last:
        # print_exception(last)  # â† ì£¼ì„ ì²˜ë¦¬(í˜¹ì€ í™˜ê²½ë³€ìˆ˜ë¡œ í† ê¸€)
        print("[call_llm_json] giving up after retries")
    return None


def call_llm_json(
    *,
    system: str,
    user: str,
    temperature: float = 0.3,
    max_tokens: int = 4000,
    trace_id: Optional[str] = None,
    timeout_s: Optional[float] = None,
    retries: int = 2,   # â† ì¶”ê°€
) -> Dict[str, Any]:
    """
    openai_config.chat_completion()ì„ ê°ì‹¸ JSONì„ ë°˜í™˜.
    - Azure/OpenAI/Gemini ëª¨ë‘ openai_configì˜ ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤.
    - ëª¨ë¸ì´ JSONë§Œ ë°˜í™˜í•˜ì§€ ì•Šì•„ë„ ë³¸ë¬¸ì—ì„œ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    - ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ëŒ€ì‹  {"ok": False, "candidates": []} ë°˜í™˜(ìƒìœ„ ì„œë¹„ìŠ¤ê°€ í´ë°± ê°€ëŠ¥).
    """
    def _once() -> Dict[str, Any]:
        messages = [
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ]
        # âœ… ê°€ëŠ¥í•œ ê²½ìš° JSON ì „ìš© ì‘ë‹µ ê°•ì œ
        extra_kwargs = {}
        try:
            # Azure OpenAI 2024-12-01-preview ì§€ì›
            extra_kwargs["response_format"] = {"type": "json_object"}
        except Exception:
            pass

        text = chat_completion(
            messages,
            trace_id=trace_id,
            temperature=temperature if temperature is not None else DEFAULT_TEMPERATURE,
            max_tokens=max_tokens if max_tokens is not None else min(DEFAULT_MAX_TOKENS, 1000),
            timeout_s=timeout_s if timeout_s is not None else DEFAULT_TIMEOUT_S,
            **extra_kwargs,
        )
        # LLM ì›ë¬¸ -> ì œì–´ë¬¸ì ì œê±° -> JSON ì¶”ì¶œê¸°
        raw_text = text or ""
        print("&&&&&&&&&&&&&&&&&&&&&&&&", raw_text)
        clean_text = CONTROL_CHARS_RE.sub(' ', raw_text)
        data = _extract_json(clean_text)          # âœ… ì—¬ê¸°ì„œ JSON íŒŒì‹±
        data = strip_controls_deep(data)          # âœ… íŒŒì‹± ê²°ê³¼ ì œì–´ë¬¸ì ì •ë¦¬
        data = normalize_quotes_deep(data)        # âœ… íŒŒì‹± "í›„" ì•ˆì „í•œ ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ ì •ê·œí™”
        return data

    # âœ… ì¬ì‹œë„ëŠ” ë°”ê¹¥ í•œ êµ°ë°ì—ì„œë§Œ!
    data = _retry(_once, retries=retries, backoff=0.8)
    if data is None:
        return {"ok": False, "candidates": []}
    if isinstance(data, dict) and "ok" not in data:
        data["ok"] = True
    return data
