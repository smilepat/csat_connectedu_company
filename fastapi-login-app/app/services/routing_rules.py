from __future__ import annotations
import os
import re
from typing import List, Dict
from app.specs.passage_preprocessor import sanitize_user_passage
from app.services.llm_client import call_llm_json  # (ìœ ì§€)

"""
Rule-based candidate suggester (format + content hybrid).
- Returns up to 12 candidates sorted by fit(desc).
- Adds RC30 even WITHOUT underline markers if lexical/nuance signals exist,
  or when circled numerals are followed by short lexical candidates.
- 2025-09 ì—…ë°ì´íŠ¸:
  Â· RC18~RC41 "ìµœì¢… í†µí•©í‘œ" ë°˜ì˜: ê¸¸ì´/ë‹´í™”/í¬ë§· ì‹ í˜¸ ê¸°ë°˜ ë³´ì • ë ˆì´ì–´ ì¶”ê°€
  Â· ê¸¸ì´ êµ¬ê°„(ì§§ìŒ/ì¤‘ê°„/ê¹€) + í‘œë©´ ì‹ í˜¸(ë²ˆí˜¸/ë¼ë²¨/ê³µì§€/ì„œì‹ ) + ë‚´ìš© ì‹ í˜¸(ì •ì„œ/ê¶Œê³ /ë¹„ìœ /ë„í‘œ/ì „ê¸° ë“±)
    â†’ ìœ í˜•ë³„ fitì„ ì•ˆì „í•˜ê²Œ ê°€ì‚° ë³´ì •

- 2025-09 ê¸¸ì´ ìš°ì„ (Gating) ì ìš© (ì„¸ë¶„í™” ê·œì¹™):
  Â· â‰¤150 â†’ RC33ê¹Œì§€ í—ˆìš©
  Â· 151â€“199 â†’ RC40ê¹Œì§€ í—ˆìš©
  Â· â‰¥200 â†’ RC41 ì´ìƒ(ì„¸íŠ¸í˜•) í¬í•¨ í—ˆìš©
  â€» ê¸¸ì´ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•ŠëŠ” ìœ í˜•ì€ ì–´ë–¤ ê²½ìš°ì—ë„ ì¶”ì²œì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ add/ì£¼ì…/ë³´ì • ë‹¨ê³„ ì „ì²´ì— ê²Œì´íŠ¸ ì ìš©.
"""

# ---------- Base regex signals (format-like) ----------
RE_UNDERLINE        = re.compile(r"<u>.*?</u>", re.I | re.S)
RE_NUM_BULLETS      = re.compile(r"[â‘ â‘¡â‘¢â‘£â‘¤]")
RE_INSERT_PARENS    = re.compile(r"\(\s*[â‘ â‘¡â‘¢â‘£â‘¤]\s*\)")
RE_PARAGRAPH_LABELS = re.compile(r"\([A-C]\)")
RE_LOWER_PARENS     = re.compile(r"\([a-e]\)")  # (a)(b)(c) ë¼ë²¨ ê°ì§€
RE_NOTICE_KEYS      = re.compile(
    r"\b("
    r"Title|Date|Location|Eligibility|Registration|Fee|Contact|Note|Time|Venue|"
    r"Deadline|Participants?|Age requirement|Restrictions?|Details?|Awards?|"
    r"Evaluation Criteria|Activities?|Duration|Period|Schedule|Return|Use|"
    r"Service Range|Purchase Information|Tour Times?|Renovation Period|"
    r"Areas to be Closed|Card Type|Additional Information|Caution"
    r")\s*:",
    re.I,
)
RE_RC33_PIVOT = re.compile(
    r"\b(it follows that|in turn|therefore|thus|consequently|as a result)\b",
    re.I,
)

RE_RC39_META = re.compile(
    r"\b(analogy|argument|reasoning|logic|this is why|the reason is|what's worse|in reality|in fact|not .* but|the essence of|fails to|undermine[s]?)\b",
    re.I,
)

RE_RC39_CONTRAST = re.compile(
    r"\b(by contrast|in contrast|however|but |yet |still,|nevertheless|nonetheless|on the other hand)\b",
    re.I,
)

# NEW: ì•ˆë‚´ë¬¸ ì „ìš© ë³´ì¡° ì‹ í˜¸
RE_BULLET_DOT       = re.compile(r"[âˆ™â€¢]|^\s*[-*]\s", re.M)
RE_PRICE_SIGN       = re.compile(r"[$ï¿¡â‚¬]\s*\d", re.I)

RE_TABLEY           = re.compile(r"\b(table|figure|chart|graph)\b", re.I)
RE_CHARTY           = re.compile(r"\b(percent|percentage|survey|dataset|index|rank(ed)?|ratio|per capita|growth rate|decline|increase)\b", re.I)
RE_BIO = re.compile(
    r"\b("
    r"born\b|born in|was born in|"      # ì¶œìƒ
    r"died in|passed away|"             # ì‚¬ë§
    r"awarded|won the|"                 # ìƒÂ·ìˆ˜ìƒ
    r"career|early life|later years|retired|"  # ê²½ë ¥/ìƒì• 
    r"biograph|Nobel|prize"             # ì „ê¸°/ë…¸ë²¨ ë“±
    r")\b",
    re.I,
)
RE_ARGUMENT         = re.compile(
    r"\b("
    r"should|must|ought to|need to|have to|has to|"
    r"it is necessary to|"
    r"it is (?:important|essential|crucial|critical) to|"
    r"it is desirable that|"
    r"it would be better to|"
    r"we (?:have|need to)"
    r")\b",
    re.I,
)
RE_EMOTION          = re.compile(r"\b(feel|felt|anxious|relieved|disappointed|excited|upset|proud|afraid|confident|confidence)\b", re.I)

# ì‹¤í—˜Â·ì—°êµ¬Â·ë°ì´í„° ê¸°ë°˜ ë¬˜ì‚¬ (RC37 ìª½ìœ¼ë¡œ ê°•í•˜ê²Œ ë³´ë‚´ê³  ì‹¶ì€ íŒ¨í„´)
RE_RC_EXP_LIKE = re.compile(
    r"\b("
    r"experiment|experimental|research|study|studies|"
    r"data|dataset|measurements?|subjects?|participants?|"
    r"they found that|we found that|results? (?:show|suggest|indicate)|"
    r"observed that|observations? of|"
    r"patterns? of|scanning"
    r")\b",
    re.I,
)

# â–¶ RC37: ì§„ì§œ 'ì‹¤í—˜ ë³´ê³ í˜•' ì‹ í˜¸ (ê°•í•œ RC37 íŒíŠ¸)
RE_RC37_STRONG_EXP = re.compile(
    r"\b("
    r"experiment|experimental|"
    r"randomi[sz]ed|control group|treatment group|placebo|"
    r"subjects?|participants?|"
    r"in one study|in a study|in an experiment"
    r")\b",
    re.I,
)

# â–¶ RC37: ë…¼ì¦/ì´ë¡ /ëª¨í˜•/ê· í˜• ë“± 'ë‹¨ê³„ì  ë…¼ì¦' ë©”íƒ€ ë‹¨ì–´
RE_RC37_REASONING_META = re.compile(
    r"\b("
    r"assume|assumption|principle|theory|model|"
    r"equilibrium|equilibria|outcome|outcomes|scenario|"
    r"case in which|cases? where"
    r")\b",
    re.I,
)

# â–¶ RC37: ì¸ê³¼ ì—°ì‡„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ‘ì†ì‚¬ (ë”°ë¼ì„œ, ê·¸ ê²°ê³¼, ê·¸ëŸ¬ë¯€ë¡œâ€¦)
RE_RC37_CAUSAL_CHAIN = re.compile(
    r"\b("
    r"therefore|thus|consequently|as a result|hence|in turn"
    r")\b",
    re.I,
)

# â–¶ RC36: ì •ì˜/ìš©ì–´ ì†Œê°œ ì‹ í˜¸
RE_RC36_DEF_CUE = re.compile(
    r"\b(is|are|was|were)\s+(called|known as|defined as)\b"
    r"|\b(refers to|means that)\b",
    re.I,
)

# â–¶ RC36: ì˜ˆì‹œ/ë¹„êµ ì „ê°œ ì‹ í˜¸ (ê¸°ì¡´)
RE_RC36_EXAMPLE_CUE = re.compile(
    r"\b("
    r"for example|for instance|similarly|in particular|"
    r"in this sense|in practice|in the real world"
    r")\b",
    re.I,
)

# RC19ìš© ê°ì • polarity ì„¸íŠ¸ + ì „í™˜ ì‹œê·¸ë„
POS_EMO = {
    "relieved", "confident", "confidence", "excited", "proud",
    "joy", "joyful", "happy", "glad", "satisfied", "at peace"
}
NEG_EMO = {
    "anxious", "uneasy", "upset", "afraid", "nervous",
    "disappointed", "frustrated", "shaking", "troubled", "worried"
}
RE_TURNING = re.compile(
    r"\b(However|But|Then|Finally|At last|After (he|she|I)|After hearing)\b",
    re.I,
)

RE_IDIOM_SHELLS = [
    re.compile(r"\bthe\s+[a-z]+?\s+in\s+the\s+room\b", re.I),
    re.compile(r"\b[a-z]+-?ed\s+sword\b", re.I),
    re.compile(r"\bball\s+is\s+in\s+(?:my|your|his|her|their|our)\s+court\b", re.I),
    re.compile(r"\bon\s+thin\s+ice\b", re.I),
    re.compile(r"\bglass\s+ceiling\b", re.I),
    re.compile(r"\bslippery\s+slope\b", re.I),
]
RE_SIMILE = re.compile(r"\b(?:like|as)\s+(?:a|an|the)?\s*[A-Za-z][A-Za-z\-']{3,}", re.I)

METAPHOR_CUES = {
    "iceberg", "elephant", "sword", "ceiling", "slope", "anchor",
    "compass", "pillar", "bridge", "lens", "canvas", "blind trust"
}

# ---------- RC29/RC30: extra semantic/lexical signals (content-based) ----------
RE_CIRCLED          = re.compile(r"[â‘ â‘¡â‘¢â‘£â‘¤]")
RE_INLINE_LEX       = re.compile(r"[â‘ â‘¡â‘¢â‘£â‘¤]\s*[A-Za-zê°€-í£\-]+(?:\s+[A-Za-zê°€-í£\-]+){0,2}")

RE_LEXICAL_META     = re.compile(
    r"\b(word\s*choice|lexical|collocation|nuance|synonym|antonym|appropriate|inappropriate)\b",
    re.I
)
RE_CONTRAST_EVAL    = re.compile(
    r"\b(irrelevant|inaccurate|misleading|awkward|odd|inapt|ill[-\s]?fitted|ill[-\s]?chosen|off)\b.*?\b"
    r"(relevant|accurate|apt|fitting|well[-\s]?chosen|on[-\s]?point|natural)\b|"
    r"\b(relevant|accurate|apt|fitting|well[-\s]?chosen|on[-\s]?point|natural)\b.*?\b"
    r"(irrelevant|inaccurate|misleading|awkward|odd|inapt|ill[-\s]?fitted|ill[-\s]?chosen|off)\b",
    re.I | re.S
)
RE_DERIV            = re.compile(r"\b\w+(?:ness|tion|sion|ity|able|ible|ive|al|ly|ment|ize|ise|ous)\b", re.I)

RE_GRAMMAR_META     = re.compile(
    r"\b(tense|agreement|subject[-\s]?verb|preposition|article|pronoun|parallelism|comparative|superlative|"
    r"modifier|participle|gerund|infinitive|voice|case|concord)\b",
    re.I
)

# ---------- Set-type signals (RC41â€“RC42) ----------
RE_ROMAN_PARENS     = re.compile(r"\(\s*(?:i|ii|iii|iv|v)\s*\)", re.I)  # (i)(ii)(iii)...
RE_PART_HEADING     = re.compile(r"\bPart\s*(?:I|II|III|1|2|3)\b", re.I)
RE_SECTION_HEAD     = re.compile(r"\bSection\s*[A-C1-3]\b", re.I)
RE_Q_RANGE          = re.compile(r"\bQuestions?\s*(?:\d+\s*[-â€“]\s*\d+|\d+\s*(?:and|&)\s*\d+)\b", re.I)
RE_FORMER_LATTER    = re.compile(r"\b(the\s+former|the\s+latter|respectively)\b", re.I)
RE_REF_PASSAGE      = re.compile(r"\b(in|from)\s+(?:passage|paragraph|text)\s*\(?[a-e]\)?\b", re.I)

# ---------- Extra signals for RC18/27/28 ----------
RE_LETTER_DEAR      = re.compile(r"\b(Dear\s+[A-Z][a-zA-Z]+|To whom it may concern|Dear\s+Friends)\b")
RE_LETTER_CLOSE     = re.compile(r"\b(Sincerely|Regards|Best regards|Yours truly|Many blessings)\b")
RE_WEBSITE_URL      = re.compile(r"https?://|www\.", re.I)

# NEW: RC18 intent / purpose signals
RE_INTENT_REQUEST = re.compile(
    r"\b(I would like to (?:ask|request)|Please let me know|I ask you to|"
    r"I want immediate action)\b",
    re.I,
)

RE_INTENT_INQUIRY = re.compile(
    r"\b(I am writing to inquire|I would like to know|I want to know|"
    r"could not find (?:any )?information)\b",
    re.I,
)

RE_INTENT_GUIDE = re.compile(
    r"\b(This is how you participate|Here is how you participate|"
    r"You can bring your items for donation|You can bring your items)\b",
    re.I,
)

# â˜… ê´‘ê³ /ì•ˆë‚´í˜• ì˜ë„ í‘œí˜„ (ì›¹íˆ° ì˜ˆì‹œ ëŒ€ì‘)
RE_INTENT_PROMO = re.compile(
    r"\bIf you'?re interested in\b|\bThis post is for you\b|\bIt'?s time to\b",
    re.I,
)
RE_RC38_PIVOT = re.compile(
    r"\b("
    r"yes,|however,|but |in fact,|indeed,|"
    r"for example,|by way of example,|"
    r"without\b|once\b|thus,"
    r")",
    re.I,
)

def _looks_rc39_argument_insertion(
    txt: str,
    m: Dict[str, float],
    strong_emotion_shift: bool,
    notice_like: bool,
) -> bool:
    """
    RC39(ê³ ë‚œë„ ë¬¸ì¥ ì‚½ì…) 'ê¹¨ë—í•œ ì§€ë¬¸' íŒë³„:

    - ë‹¨ì¼ ì£¼ì œì˜ ì„¤ëª…/ë¶„ì„/ë…¼ì¦ ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic),
    - ê³µì§€/ì„œì‹ /ê°•í•œ ê°ì • ì„œì‚¬ëŠ” ì œì™¸,
    - ê¸¸ì´ 130~260 í† í°, ë¬¸ì¥ ìˆ˜ 5ê°œ ì´ìƒ,
    - 'analogy, argument, reasoning, logic' ê°™ì€ ë…¼ì¦ ë©”íƒ€ ë‹¨ì–´ê°€ ìˆê³ ,
    - 'by contrast, nevertheless, still, on the other hand' ê°™ì€ ê°•í•œ ëŒ€ì¡°/ë°˜ì „ ì‹ í˜¸ê°€ í•¨ê»˜ ì¡´ì¬í•  ê²ƒ.
    """
    if not txt:
        return False

    if notice_like or strong_emotion_shift:
        return False

    # ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ëª…/ë…¼ì¦í˜• ì§€ë¬¸ì¸ì§€ í™•ì¸
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)

    if tok < 130 or tok > 260:
        return False
    if sent < 5:
        return False

    # ë…¼ì¦ ë©”íƒ€ + ëŒ€ì¡° ì‹ í˜¸ê°€ ë™ì‹œì— ìˆëŠ” ê²½ìš°ë§Œ RC39ë¡œ ë³¸ë‹¤
    if not RE_RC39_META.search(txt):
        return False
    if not RE_RC39_CONTRAST.search(txt):
        return False

    return True


# ---------- Toggle: RC21 pass-through to LLM ----------
FORCE_RC21_PASS = os.getenv("FORCE_RC21_PASS", "1").lower() in ("1", "true", "yes", "on")

# âœ… ---------- Evergreen types ----------
"""
EVERGREEN_TYPES = [
    "RC22", "RC23", "RC24"
]

_EVERGREEN_BASE_FIT = {
    "RC22": 0.46, "RC23": 0.46, "RC24": 0.44
}
"""
EVERGREEN_TYPES = [
    "RC22", "RC23", "RC24", "RC40",
    #"RC31", "RC32", "RC33",
    # "RC29",  # âŒ Evergreenì—ì„œ ì œê±°
    "RC30",  # ì–´íœ˜ ì ì ˆì„±ì€ ì—¬ì „íˆ ë²”ìš© í›„ë³´ë¡œ ìœ ì§€
    "RC41", "RC42",
]

_EVERGREEN_BASE_FIT = {
    "RC22": 0.46, "RC23": 0.46, "RC24": 0.44, "RC40": 0.42,
    #"RC31": 0.45, "RC32": 0.45, "RC33": 0.43,
    # "RC29": 0.48,  # âŒ í•„ìš” ì—†ìœ¼ë©´ ì‚­ì œí•´ë„ ë˜ê³ , ë‚¨ê²¨ë‘¬ë„ ì‹¤ì œë¡œëŠ” ì•ˆ ì“°ì„
    "RC30": 0.47,
    "RC41": 0.41, "RC42": 0.41,
}

# ---------- NEW: Length-first gating (ì„¸ë¶„í™”) ----------
# â‰¤150 â†’ RC33ê¹Œì§€, 151â€“199 â†’ RC40ê¹Œì§€, â‰¥200 â†’ RC41+
def _length_band(tokens: int) -> str:
    if tokens <= 150:
        return "upto_rc33"
    if tokens < 200:
        return "upto_rc40"
    return "rc41_plus"

# ê¸¸ì´ ë°´ë“œë³„ í—ˆìš© ìœ í˜•(ê²€ì¶œ/ì£¼ì…/ë³´ì • ëª¨ë‘ ì´ ì§‘í•©ì„ í†µê³¼í•´ì•¼ í•¨)
ALLOW_BY_LENGTH = {
    "upto_rc33": {
        "RC18","RC19","RC20","RC21","RC22","RC23","RC24",
        "RC25", "RC26",  # âœ… ì§§ì€ í‘œ/ê·¸ë˜í”„ ì„¤ëª… ì§€ë¬¸ë„ RC25 í—ˆìš©
        "RC27","RC28","RC29","RC30",
        "RC31","RC32","RC33",
    },
    "upto_rc40": {
        "RC18","RC19","RC20","RC21","RC22","RC23","RC24",
        "RC25","RC26","RC27","RC28","RC29","RC30",
        "RC31","RC32","RC33","RC34","RC35","RC36","RC37","RC38","RC39","RC40",
    },
    "rc41_plus": {
        "RC18","RC19","RC20","RC21","RC22","RC23","RC24",
        "RC25","RC26","RC27","RC28","RC29","RC30",
        "RC31","RC32","RC33","RC34","RC35","RC36","RC37","RC38","RC39","RC40",
        "RC41","RC42",
    },
}

# ---------- Scorers ----------
def _score_rc30_semantic(text: str) -> float:
    score = 0.0
    if RE_LEXICAL_META.search(text):
        score += 0.35
    if RE_CONTRAST_EVAL.search(text):
        score += 0.25
    if len(RE_DERIV.findall(text)) >= 3:
        score += 0.10
    return min(0.80, score)

def _score_rc29_semantic(text: str) -> float:
    score = 0.0
    if RE_GRAMMAR_META.search(text):
        score += 0.30
    return min(0.55, score)

def _score_rc29_structure(text: str) -> float:
    """
    â˜… ì¸ìš© ëª¨ë“œìš© RC29 êµ¬ì¡° ìŠ¤ì½”ì–´ëŸ¬
    - â‘ ~â‘¤, ë°‘ì¤„ì´ ì „ì²˜ë¦¬ì—ì„œ ì‚¬ë¼ì§„ ìƒíƒœì—ì„œë„
      'ë¬¸ì¥ êµ¬ì¡°'ë§Œ ë³´ê³  ë¬¸ë²• íŒë‹¨(RC29) ì í•©ì„±ì„ ì¶”ì •.
    - ì „í˜•ì ì¸ RC29 ì§€ë¬¸ íŒ¨í„´:
      Â· 90~220ë‹¨ì–´ ì •ë„ì˜ ì„¤ëª…/ë¶„ì„ ì§€ë¬¸
      Â· ë¬¸ì¥ ìˆ˜ 4ê°œ ì´ìƒ
      Â· ê´€ê³„ì‚¬/ì¢…ì†ì ˆ/ë¶„ì‚¬êµ¬ ë“± ë¬¸ë²• í¬ì¸íŠ¸ê°€ êµ°ë°êµ°ë° ì¡´ì¬
    """
    if not text:
        return 0.0

    tokens = re.findall(r"[A-Za-z']+|\d+%?", text)
    tok = len(tokens)
    if tok < 60 or tok > 260:
        return 0.0

    sent_cnt = max(1, len(re.findall(r"[.!?]+(?:\s|$)", text)))
    if sent_cnt < 4:
        return 0.0

    lc = text.lower()
    rel_hits = len(re.findall(r"\b(which|that|who|whom|whose|where|when)\b", lc))
    sub_hits = len(re.findall(r"\b(because|although|though|while|when|if|unless|since|after|before)\b", lc))
    aux_hits = len(re.findall(
        r"\b(am|is|are|was|were|has|have|had|do|does|did|can|could|should|would|must|may|might)\b",
        lc,
    ))

    score = 0.0
    if rel_hits >= 2:
        score += 0.25
    elif rel_hits == 1:
        score += 0.15

    if sub_hits >= 2:
        score += 0.20
    elif sub_hits == 1:
        score += 0.10

    if sent_cnt >= 5:
        score += 0.10
    if tok >= 100:
        score += 0.10
    if aux_hits >= 10:
        score += 0.05

    # ìƒí•œì€ ëŒ€ëµ 0.65 ì •ë„ë¡œ ë‘ê³ , ë‚˜ë¨¸ì§€ëŠ” length/signal boostì—ì„œ ë” ì–¹ì–´ ì¤„ ìˆ˜ ìˆê²Œ
    return min(0.65, score)

def _score_rc21_semantic(text: str, *, has_bullets: bool, has_underline: bool, has_insert_mark: bool) -> float:
    """
    RC21: ë¬¸ë§¥ ê¸°ë°˜ ì˜ë¯¸/ë¹„ìœ /ê´€ìš© í‘œí˜„ í•´ì„ ê°€ëŠ¥ì„± ìŠ¤ì½”ì–´ë§.
    - í˜•ì‹(â‘ ~â‘¤, ë°‘ì¤„, ì‚½ì…í‘œì‹œ)ì´ ìˆì–´ë„ ë¹„ìœ /ê´€ìš© ì‹ í˜¸ê°€ ê°•í•˜ë©´ RC21 í›„ë³´ë¡œ ì¸ì •.
    - ë‹¤ë§Œ ê°•í•œ í˜•ì‹ ì‹ í˜¸(â‘ ~â‘¤ + ë°‘ì¤„ ë“±)ê°€ ìˆìœ¼ë©´ RC29/30/35/38ê³¼ì˜ ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ì†Œí­ ê°ì‡ .
    """
    shell_hit = any(p.search(text) for p in RE_IDIOM_SHELLS)
    simile_hit = bool(RE_SIMILE.search(text))
    lc = text.lower()
    cue_hits = sum(1 for w in METAPHOR_CUES if w in lc)

    score = 0.0
    if shell_hit:
        score += 0.50    # ê´€ìš©êµ¬ íŒ¨í„´ (the ~ in the room, on thin ice ë“±)
    if simile_hit:
        score += 0.30    # like / as ~ ì§ìœ  íŒ¨í„´
    if cue_hits >= 2:
        score += 0.20    # ë¹„ìœ  ë‹¨ì–´ê°€ ì—¬ëŸ¬ ê°œ
    elif cue_hits == 1:
        score += 0.10    # ë¹„ìœ  ë‹¨ì–´ 1ê°œ

    # í˜•ì‹ ì‹ í˜¸ê°€ ê°•í•˜ë©´ RC29/30/35/38ì´ ë” ìš°ì„ ì´ë¯€ë¡œ ì•½ê°„ ê°ì‡ 
    if has_bullets or has_underline or has_insert_mark:
        score *= 0.85

    return score


def _score_set_signals(text: str) -> dict:
    t = text or ""
    score_41 = score_42 = 0.0
    if RE_LOWER_PARENS.search(t):     score_41 += 0.18; score_42 += 0.15
    if RE_ROMAN_PARENS.search(t):     score_41 += 0.10; score_42 += 0.08
    if RE_PART_HEADING.search(t):     score_41 += 0.08; score_42 += 0.06
    if RE_SECTION_HEAD.search(t):     score_41 += 0.06; score_42 += 0.05
    if RE_Q_RANGE.search(t):          score_41 += 0.07; score_42 += 0.06
    if RE_FORMER_LATTER.search(t):    score_41 += 0.05; score_42 += 0.05
    if RE_REF_PASSAGE.search(t):      score_41 += 0.06; score_42 += 0.06
    para_cnt = max(1, t.count("\n\n") + 1)
    if para_cnt >= 2:
        boost = min(0.06, 0.02 * (para_cnt - 1))
        score_41 += boost; score_42 += boost
    score_41 = min(score_41, 0.30)
    score_42 = min(score_42, 0.28)
    return {"rc41": score_41, "rc42": score_42}

# âœ… Evergreen ì£¼ì… ìœ í‹¸ (ê¸¸ì´ ê²Œì´íŠ¸ ì ìš©)
def _inject_evergreen_candidates(cands: List[Dict], passage: str, allowed_types: set[str]) -> List[Dict]:
    existing = {c.get("type") for c in cands}

    # ê¸¸ì´/ê¸°ì´ˆ í†µê³„
    metrics = _basic_counts(passage or "")
    notice_like = _is_notice_like(passage or "", metrics)

    has_strong_format = bool(
        RE_NOTICE_KEYS.search(passage)
        or RE_INSERT_PARENS.search(passage)
        or RE_UNDERLINE.search(passage)
        or notice_like
    )
    boost = 0.0 if has_strong_format else 0.03

    # ğŸ”‘ ì „ê¸°í˜•(ê°œì¸ ìƒì• ) ì§€ë¬¸ì¸ì§€ ì—¬ë¶€
    is_bio_passage = bool(RE_BIO.search(passage))

    # ì „ê¸°í˜•ì¼ ë•ŒëŠ” ì œëª©/ì£¼ì œ/ìš”ì§€/ë¹ˆì¹¸/ABìš”ì•½ Evergreenì€ ì£¼ì…í•˜ì§€ ì•ŠëŠ”ë‹¤.
    BIO_BLOCKED_EVERGREEN = {
        "RC22", "RC23", "RC24",  # ìš”ì§€/ì£¼ì œ/ì œëª©
        "RC31", "RC32", "RC33",  # ë¹ˆì¹¸
        "RC40",                  # AB ìš”ì•½
    }

    # ì•ˆë‚´ë¬¸(Notice)ì¼ ë•ŒëŠ” ì£¼ì œ/ìš”ì§€/ì œëª© + ë¹ˆì¹¸/AB ìš”ì•½ Evergreenë„ ì£¼ì…í•˜ì§€ ì•ŠëŠ”ë‹¤.
    NOTICE_BLOCKED_EVERGREEN = {
        "RC22", "RC23", "RC24",
        "RC31", "RC32", "RC33",
        "RC40",
    }

    for t in EVERGREEN_TYPES:
        if t not in allowed_types:
            continue

        # ì „ê¸°í˜• ì§€ë¬¸ì´ë©´ ìœ„ íƒ€ì…ë“¤ì€ ìŠ¤í‚µ â†’ RC26ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‘ë“œëŸ¬ì§€ê²Œ í•¨
        if is_bio_passage and t in BIO_BLOCKED_EVERGREEN:
            continue

        # ì•ˆë‚´ë¬¸ ì§€ë¬¸ì´ë©´ ìš”ì§€/ì£¼ì œ/ì œëª©/ë¹ˆì¹¸/ABìš”ì•½ Evergreenì€ ìŠ¤í‚µ â†’ RC27ì´ ë‘ë“œëŸ¬ì§€ê²Œ í•¨
        if notice_like and t in NOTICE_BLOCKED_EVERGREEN:
            continue

        if t not in existing:
            base = _EVERGREEN_BASE_FIT.get(t, 0.45)
            cands.append({
                "type": t,
                "fit": float(max(0.0, min(1.0, base + boost))),
                "reason": "í˜•ì‹ ì‹ í˜¸ ì—†ì–´ë„ ë²”ìš© ì¶œì œê°€ ê°€ëŠ¥í•œ Evergreen ìœ í˜•",
                "prep_hint": "ì§€ë¬¸ ì „ë°˜ì˜ ë…¼ë¦¬/êµ¬ë¬¸/ì–´íœ˜ ì ê²€"
            })
    return cands

def _llm_rc29_feasible(passage: str) -> bool:
    if not passage or len(passage.split()) < 30:
        return False
    user = (
        "Goal: Decide if RC29 (Grammar Judgment) is feasible for the given passage *without rewriting it*.\n\n"
        "STRICT RULES:\n"
        "- Do NOT rewrite, add, delete, or reorder any part of the passage.\n"
        "- Decide feasibility ONLY: whether you could pick 5 short spans (1â€“3 tokens) as underlined targets "
        "and make exactly ONE of them ungrammatical while the others remain correct in context.\n"
        "- Candidate grammar points to consider: relative (that/which/who/when/where), S/V agreement or tense, "
        "modal+base (must/should/can + V), passive (be + p.p.), participle (-ing/-ed phrase).\n\n"
        "OUTPUT JSON ONLY (choose exactly one):\n"
        "1) {{\n"
        '   "feasible": true\n'
        "}}\n"
        "2) {{\n"
        '   "feasible": false\n'
        "}}\n\n"
        "Passage:\n"
        "```passage\n"
        f"{passage}\n"
        "```"
    )
    try:
        resp = call_llm_json(
            system=("You evaluate feasibility for CSAT RC29 using ONLY the provided passage. "
                    "Return JSON only. No commentary."),
            user=user,
            temperature=0.0,
            max_tokens=80,
        )
        return bool(resp.get("feasible") is True)
    except Exception:
        return False

def _collapse_set_groups(cands: List[Dict]) -> List[Dict]:
    by_type = {c["type"]: c for c in cands}
    out = cands[:]

    def _remove(types):
        nonlocal out
        tset = set(types)
        out = [c for c in out if c.get("type") not in tset]

    # RC41 & RC42ë¥¼ í•˜ë‚˜ì˜ ì„¸íŠ¸ë¡œ ë³‘í•©
    if "RC41" in by_type and "RC42" in by_type:
        fit = max(by_type["RC41"]["fit"], by_type["RC42"]["fit"])
        _remove(["RC41", "RC42"])
        out.append({
            "type": "RC41",
            "fit": float(fit),
            "reason": "ì„¸íŠ¸ ì§€ë¬¸: í•˜ìœ„ ë¬¸í•­ 2ê°œ ë™ì‹œ ìƒì„± ì í•©",
            "prep_hint": "ì„¸íŠ¸ ì„ íƒ ì‹œ ë©¤ë²„ ì „ë¶€ ìƒì„±",
            "ui_label": "RC41_42",
            "members": ["RC41", "RC42"],
        })

    out = sorted(out, key=lambda x: x["fit"], reverse=True)
    return out[:12]

# ---------- NEW: Lightweight metrics & boosts ----------
DISCOURSE_MARKERS = {
    "however","nevertheless","nonetheless","instead","rather",
    "therefore","thus","consequently","hence","as a result",
    "moreover","furthermore","in","in addition","for example","for instance"
}
DEICTICS = {"this","that","these","those","it","they","which","whose","where","when"}

RE_RC40_PAIRING = re.compile(
    r"\b("
    r"on the one hand\b.*\bon the other hand\b|"  # on the one hand / on the other hand
    r"both\b.*\band\b|"                           # both A and B
    r"not only\b.*\bbut\b|"                       # not only A but (also) B
    r"while\b.*\b(but|and)\b|"                    # while A, (but/and) B
    r"whereas\b"                                  # whereas
    r")",
    re.I | re.S,
)

def _looks_expository_topic(txt: str, m: Dict[str, float]) -> bool:
    """
    RC23(ì£¼ì œ íŒŒì•…)ì— íŠ¹íˆ ì˜ ë§ëŠ” 'ì„¤ëª…/ë¶„ì„(expository)' ì§€ë¬¸ì¸ì§€ íŒë³„.
    - í•˜ë‚˜ì˜ ê°œë…/ë…¼ì§€ë¥¼ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ í’€ì–´ ì„¤ëª…í•˜ëŠ” ì „í˜•ì ì¸ ì„¤ëª…ë¬¸.
    - í¸ì§€/ê³µì§€/ì „ê¸°/í‘œÂ·ê·¸ë˜í”„/ê°•í•œ ê°ì • ë³€í™”/ì„œì‚¬ì  ìš”ì†ŒëŠ” ì—†ìŒ.
    - íŒ¨í„´ ì‹ í˜¸(â‘ , (A), ë°‘ì¤„ ë“±)ëŠ” ê³ ë ¤í•˜ì§€ ì•ŠìŒ(ìˆì–´ë„/ì—†ì–´ë„ ìƒê´€ X).
    """
    t = txt or ""
    lc = t.lower()

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)
    dm_cnt = m.get("dm_cnt", 0)

    # 1) ê¸¸ì´: ì–´ëŠ ì •ë„ ê¸´ ë‹¨ì¼ ì„¤ëª…ë¬¸
    if tok < 90:
        return False
    if sent < 3:
        return False

    # 2) í¸ì§€/ê³µì§€/ì „ê¸°/ì›¹ ê³µì§€ ê°™ì€ í˜•ì‹ì€ ì œì™¸
    if RE_NOTICE_KEYS.search(t):
        return False
    if RE_BIO.search(t):
        return False
    if RE_LETTER_DEAR.search(t) or RE_LETTER_CLOSE.search(t):
        return False
    if RE_WEBSITE_URL.search(t):
        return False

    # 3) ê°•í•œ ê°ì • ë³€í™”(ì„œì‚¬í˜•)ëŠ” ì œì™¸
    neg_hits = sum(1 for w in NEG_EMO if w in lc)
    pos_hits = sum(1 for w in POS_EMO if w in lc)
    has_turning = bool(RE_TURNING.search(t))
    if (neg_hits > 0 and pos_hits > 0) or (has_turning and RE_EMOTION.search(t)):
        return False

    # 4) ë…¼ë¦¬ ì „ê°œìš© ë‹´í™”í‘œì§€ê°€ ì–´ëŠ ì •ë„ ìˆëŠ” ì„¤ëª…/ë¶„ì„ ìŠ¤íƒ€ì¼
    #    (however, therefore, for example, in addition ë“±)
    if dm_cnt < 2:
        return False

    # 5) 'ë‹¹ìœ„/ê¶Œê³ ' ì¤‘ì‹¬ì˜ ê°•í•œ ì„¤ë“ë¬¸(RC20 ìˆœìˆ˜í˜•)ì€ ì‚´ì§ ì œì™¸
    #    (ë‹¨ìˆœíˆ "we argue that" ê°™ì€ í‘œí˜„ì€ ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§€ì§€ ì•ŠìŒ)
    if RE_ARGUMENT.search(t) and dm_cnt == 0:
        # ë‹¹ìœ„ í‘œí˜„ë§Œ ìˆê³  ë…¼ë¦¬ ì „ê°œ í‘œì§€ ê±°ì˜ ì—†ìœ¼ë©´ RC20 ìª½ì— ë” ê°€ê¹ë‹¤ê³  ë³´ê³  ì œì™¸
        return False

    return True


def _looks_rc31_blank_friendly(txt: str, m: Dict[str, float]) -> bool:
    """
    RC31(í•µì‹¬ ê°œë… ë‹¨ì–´ ë¹ˆì¹¸) ì í•© ì§€ë¬¸ì¸ì§€ ì¶”ê°€ë¡œ í•„í„°ë§.
    - ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì„¤ëª…/ë¶„ì„(expository) ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic ê¸°ë°˜),
    - ë²ˆí˜¸/ë¼ë²¨/ì‚½ì…í‘œ ë“± ë‹¤ë¥¸ ìœ í˜• ì‹ í˜¸ê°€ ì—†ì–´ì•¼ í•˜ë©°,
    - ë¬¸ì¥ ê¸¸ì´ê°€ ì–´ëŠ ì •ë„ ê¸¸ì–´ 'í•µì‹¬ ê°œë…'ì„ ë¹„ì›Œë‘ê¸° ì¢‹ì€ êµ¬ì¡°ì¼ ê²ƒ.
    """
    if not txt:
        return False

    # 1) ë¨¼ì € ì „í˜•ì ì¸ ì„¤ëª…ë¬¸ì¸ì§€ í™•ì¸ (í¸ì§€/ê³µì§€/ì „ê¸°/ê°ì • ë³€í™” ë“± ì´ë¯¸ ì œì™¸)
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    avg_len = m.get("avg_len", 0.0)

    # 2) ê¸¸ì´ ë²”ìœ„: RC31 ë‹¨ì¼ ì§€ë¬¸ì— ì í•©í•œ ëŒ€ëµì ì¸ êµ¬ê°„
    if tok < 90 or tok > 260:
        return False

    # 3) ë‹¤ë¥¸ í˜•ì‹ ì‹ í˜¸ê°€ ìˆìœ¼ë©´ RC31ë¡œ ì“°ê¸° ì–´ë µë‹¤ê³  ë³¸ë‹¤
    #   - â‘ ~â‘¤, ( â‘  ) : RC29/30/35/38 ê³„ì—´
    #   - (A)(B)(C)    : RC36/37 ê³„ì—´
    #   - (a)(b)(c)    : RC41/42 ì„¸íŠ¸í˜•
    if RE_NUM_BULLETS.search(txt):
        return False
    if RE_INSERT_PARENS.search(txt):
        return False
    if RE_PARAGRAPH_LABELS.search(txt):
        return False
    if RE_LOWER_PARENS.search(txt):
        return False

    if avg_len < 14:
        return False

    return True

def _looks_rc33_high_level(txt: str, m: Dict[str, float]) -> bool:
    """
    RC33(ê³ ë‚œë„ êµ¬/ì ˆ ë¹ˆì¹¸) ì „í˜• íŒ¨í„´:
    - ë‹¨ì¼ ì£¼ì œì˜ ì„¤ëª…/ë¶„ì„(expository) ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic ê¸°ë°˜),
    - ê¸¸ì´ê°€ ì¶©ë¶„íˆ ê¸¸ê³ (ì¶”ìƒ ê°œë… ì „ê°œ),
    - ë¬¸ì¥ ìˆ˜ì™€ ë‹´í™”í‘œì§€/ì§€ì‹œì–´ê°€ ë§ìœ¼ë©°,
    - 'in turn', 'it follows that', 'thus' ê°™ì€ ë…¼ë¦¬ pivotì´ ë“±ì¥.
    """
    if not txt:
        return False

    # 1) ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ëª…/ë¶„ì„ ì§€ë¬¸ì´ ì•„ë‹ˆë©´ RC33 í•˜ì´ë ˆë²¨ë¡œ ë³´ì§€ ì•ŠìŒ
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)
    dm_cnt = m.get("dm_cnt", 0)
    deictic_cnt = m.get("deictic_cnt", 0)
    lc = txt.lower()

    # 2) ê¸¸ì´/ë¬¸ì¥ ìˆ˜: ì–´ëŠ ì •ë„ ì¥ë¬¸ + ë¬¸ì¥ ì—¬ëŸ¬ ê°œ
    if tok < 120 or tok > 260:
        return False
    if sent < 5:
        return False

    # 3) ë‹´í™”í‘œì§€Â·ì§€ì‹œì–´ ë§ì´ ì“°ì´ëŠ” ì¶”ìƒ ë…¼ë¦¬ ì „ê°œ
    if dm_cnt < 3:
        return False
    if deictic_cnt < 5:
        return False

    # 4) ë…¼ë¦¬ì  pivot í‘œí˜„: in turn / it follows that / thus / therefore / consequently / as a result ë“±
    if not RE_RC33_PIVOT.search(lc):
        return False

    return True

def _looks_rc34_global_blank(txt: str, m: Dict[str, float]) -> bool:
    """
    RC34(ê³ ë‚œë„ êµ¬/ì ˆ ë¹ˆì¹¸) ì „í˜• íŒ¨í„´:
    - ë‹¨ì¼ ì£¼ì œì˜ ì„¤ëª…/ë¶„ì„(expository) ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic ê¸°ë°˜),
    - RC33ë³´ë‹¤ ì¡°ê¸ˆ ë” 'ì¥ë¬¸Â·ê³ ë‚œë„'ì— ê°€ê¹ê³ ,
    - ë¬¸ì¥ ìˆ˜/ë‹´í™”í‘œì§€/ì§€ì‹œì–´ê°€ ì¶©ë¶„íˆ ë§ìœ¼ë©°,
    - ì „í™˜/ì¸ê³¼ pivot ì—­í• ì„ í•˜ëŠ” í‘œí˜„ì´ ì¡´ì¬.
      (ì˜ˆ: however, instead, on the other hand, therefore, thus, as a result, in turn ë“±)
    """
    if not txt:
        return False

    # 1) ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ëª…/ë¶„ì„ ì§€ë¬¸ì´ ì•„ë‹ˆë©´ RC34 í›„ë³´ê°€ ì•„ë‹˜
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)
    dm_cnt = m.get("dm_cnt", 0)
    deictic_cnt = m.get("deictic_cnt", 0)
    avg_len = m.get("avg_len", 0.0)
    lc = txt.lower()

    # 2) ê¸¸ì´/ë¬¸ì¥ ìˆ˜: RC33ë³´ë‹¤ ì¡°ê¸ˆ ë” ì¥ë¬¸ ìª½ì„ ìš°ì„ 
    #   - ê¸¸ì´ 140~270 ì •ë„, ë¬¸ì¥ 5ê°œ ì´ìƒ
    if tok < 140 or tok > 270:
        return False
    if sent < 5:
        return False

    # 3) ë‹´í™”í‘œì§€/ì§€ì‹œì–´ê°€ ì¶©ë¶„íˆ ë§ì•„ 'ë…¼ë¦¬ ì—°ê²°ë¶€'ê°€ í’ë¶€í•´ì•¼ í•¨
    if dm_cnt < 3:
        return False
    if deictic_cnt < 5:
        return False
    if avg_len < 16:
        return False

    # 4) ì „í™˜/ì¸ê³¼ pivot í‘œí˜„(â€œin turnâ€, â€œit follows thatâ€, â€œhoweverâ€, â€œinsteadâ€, â€œon the other handâ€ ë“±)
    pivot = bool(RE_RC33_PIVOT.search(lc) or re.search(
        r"\b(however|instead|on the other hand|but)\b", lc
    ))
    if not pivot:
        return False

    return True



def _looks_rc40_ab_summary(txt: str, m: Dict[str, float]) -> bool:
    """
    RC40(AB ìš”ì•½) ì í•© ì§€ë¬¸ íŒë³„:

    - ì „í˜•ì ì¸ ì„¤ëª…/ë¶„ì„(expository) ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic ê¸°ë°˜),
    - ë‹¨ì¼ ì£¼ì œë¥¼ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ì „ê°œí•˜ë©°,
    - 'ë‘ ê°€ì§€ ì¸¡ë©´/ìš”ì†Œ'ë¡œ ì••ì¶• ê°€ëŠ¥í•œ ëŒ€ì¡°Â·ë³´ì™„ êµ¬ì¡°ê°€ ìˆì„ ê²ƒ.
      (ì˜ˆ: ì œí•œ vs ë³´ì™„, ë¬¸ì œ vs í•´ê²°, ì›ì¸ vs ê²°ê³¼ ë“±)
    """
    if not txt:
        return False

    # 1) ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ëª…/ë¶„ì„ ì§€ë¬¸ì¸ì§€ í™•ì¸
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)
    dm_cnt = m.get("dm_cnt", 0)

    # ê¸¸ì´: ì¤‘ì¥ë¬¸ ìœ„ì£¼ (RC40ëŠ” ì„¸íŠ¸í˜•ê¹Œì§€ëŠ” ì•„ë‹˜)
    if tok < 90 or tok > 260:
        return False
    if sent < 3:
        return False

    # ë…¼ë¦¬ ì „ê°œ í‘œì§€ ìµœì†Œ 2ê°œ ì´ìƒ
    if dm_cnt < 2:
        return False

    lc = txt.lower()

    # 2) AB í˜ì–´ êµ¬ì¡° ì‹ í˜¸:
    #    - ëª…ì‹œì  í˜ì–´ë§ í‘œí˜„ (both A and B, not only A but B, on the one hand...)
    #    - í˜¹ì€ while/whereas/although ë“±ìœ¼ë¡œ ë‘ ì¸¡ë©´ì„ ë¹„êµÂ·ëŒ€ì¡°
    has_pair = bool(RE_RC40_PAIRING.search(lc))
    has_basic_contrast = bool(
        re.search(r"\b(while|whereas|although|though)\b", lc)
    )

    if not (has_pair or has_basic_contrast):
        return False

    return True

def _looks_rc35_expository_flow(
    txt: str,
    m: Dict[str, float],
    strong_emotion_shift: bool,
) -> bool:
    """
    RC35(ë¬´ê´€í•œ ë¬¸ì¥ ì°¾ê¸°) í›„ë³´ ì§€ë¬¸ íŒë³„:

    í•µì‹¬ ì¡°ê±´ (ì‚¬ìš©ì ìš”êµ¬ ë°˜ì˜):
    - ë²ˆí˜¸(â‘ ~â‘¤) ìœ ë¬´ì™€ ê´€ê³„ì—†ì´,
    - ë¬¸ì¥ì´ 5ê°œ ì´ìƒì´ë©´ RC35 ì¶œì œ 'ê°€ëŠ¥'ìœ¼ë¡œ ë³¸ë‹¤.
    - ë‹¨, ê³µì§€/ì „ê¸°/ì„œì‹ /ê°•í•œ ê°ì • ì„œì‚¬ ë“±ì€ ì œì™¸í•˜ê³ ,
      ê¸°ë³¸ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì£¼ì œë¥¼ ì„¤ëª…í•˜ëŠ” ì„¤ëª…ë¬¸(expository)ì— ê°€ê¹ê²Œ í•„í„°ë§í•œë‹¤.
    """

    if not txt:
        return False

    sent_cnt = m.get("sent", 1)
    tok = m.get("tok", 0)

    # 1) ë¬¸ì¥ ìˆ˜: 5ë¬¸ì¥ ì´ìƒì¼ ë•Œë§Œ RC35 í›„ë³´
    #    (ë„ˆë¬´ ê¸´ ì„¸íŠ¸í˜• ì¥ë¬¸ì€ RC41/42 ìª½ì´ ë” ì í•©í•˜ë¯€ë¡œ ëŒ€ëµ ìƒí•œë§Œ ë‘ )
    if sent_cnt < 5:
        return False
    if tok < 70 or tok > 260:
        return False

    # 2) ì•ˆë‚´ë¬¸/ì „ê¸°/ì„œì‹ /ì›¹ ê³µì§€ë©´ RC35ë³´ë‹¤ëŠ” ë‹¤ë¥¸ ìœ í˜•ì´ ìš°ì„ 
    if _is_notice_like(txt, m):
        return False
    if RE_NOTICE_KEYS.search(txt):
        return False
    if RE_BIO.search(txt):
        return False
    if RE_LETTER_DEAR.search(txt) or RE_LETTER_CLOSE.search(txt):
        return False
    if RE_WEBSITE_URL.search(txt):
        return False

    # 3) ê°•í•œ ê°ì • ë³€í™” ì„œì‚¬ëŠ” RC19ê°€ ë” ì í•©
    if strong_emotion_shift:
        return False

    # 4) ì„¤ëª…ë¬¸(expository)ì¸ì§€ ê°„ë‹¨íˆ ì²´í¬
    #    - ì´ë¯¸ ì •ì˜ëœ _looks_expository_topicì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ë©´ ê°€ì¥ ì•ˆì „
    if not _looks_expository_topic(txt, m):
        return False

    return True

def _looks_rc38_insertion_friendly(
    txt: str,
    m: Dict[str, float],
    strong_emotion_shift: bool,
    notice_like: bool,
) -> bool:
    """
    RC38(ë¬¸ì¥ ì‚½ì…) 'ê¹¨ë—í•œ ì§€ë¬¸' íŒë³„:

    - ë‹¨ì¼ ì£¼ì œì˜ ì„¤ëª…/ë¶„ì„(expository) ì§€ë¬¸ì´ì–´ì•¼ í•˜ê³ (_looks_expository_topic ê¸°ë°˜),
    - ê³µì§€/ì „ê¸°/ì„œì‹ /ê°•í•œ ê°ì • ì„œì‚¬ëŠ” ì œì™¸,
    - ê¸¸ì´ 120~230 í† í°, ë¬¸ì¥ ìˆ˜ 5ê°œ ì´ìƒ,
    - ì¤‘ê°„ë¶€ì— ì „í™˜/ì˜ˆì‹œ/ëŒ€ì¡° pivot ë¬¸ì¥ì´ 1ê°œ ì´ìƒ ì¡´ì¬í•  ê²ƒ.
    """
    if not txt:
        return False

    if notice_like or strong_emotion_shift:
        return False

    # ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ëª…ë¬¸ì¸ì§€ í™•ì¸
    if not _looks_expository_topic(txt, m):
        return False

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)

    if tok < 120 or tok > 230:
        return False
    if sent < 5:
        return False

    # pivot í‘œí˜„ ì¡´ì¬ ì—¬ë¶€
    if not RE_RC38_PIVOT.search(txt):
        return False

    return True

def _classify_abc_for_rc36_37(
    txt: str,
    m: Dict[str, float],
    strong_emotion_shift: bool,
) -> str:
    """
    (A)(B)(C) ë¼ë²¨ì´ ìˆëŠ” ì§€ë¬¸ì„ RC36 / RC37 / none ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜.
    - RC36: ì •ì˜/ì˜ˆì‹œ ì¤‘ì‹¬ ì¼ë°˜ ì„¤ëª…ë¬¸ ë‹¨ë½ ë°°ì—´
    - RC37: ì—°êµ¬/ì‹¤í—˜ ë³´ê³ í˜• + ë‹¨ê³„ì  ë…¼ì¦(ì¡°ê±´-ê²°ê³¼, ê· í˜•, ëª¨í˜• ë“±)
    """
    # (A)(B)(C) ë¼ë²¨ ì—†ìœ¼ë©´ ë‘˜ ë‹¤ ì•„ë‹˜
    if not RE_PARAGRAPH_LABELS.search(txt):
        return "none"

    # ì•ˆë‚´ë¬¸/ì „ê¸°/ì„œì‹ /ê°•í•œ ì •ì„œ ë³€í™”ëŠ” RC36Â·RC37 ëª¨ë‘ ì œì™¸
    if strong_emotion_shift:
        return "none"
    if _is_notice_like(txt, m):
        return "none"
    if RE_NOTICE_KEYS.search(txt):
        return "none"
    if RE_BIO.search(txt):
        return "none"
    if RE_LETTER_DEAR.search(txt) or RE_LETTER_CLOSE.search(txt):
        return "none"

    tok = m.get("tok", 0)
    sent = m.get("sent", 1)

    # ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸´ (A)(B)(C)ëŠ” ì—¬ê¸°ì„œ ë‹¤ë£¨ì§€ ì•ŠìŒ
    if tok < 70 or tok > 260:
        return "none"
    if sent < 4:
        return "none"

    lc = txt.lower()
    expository      = _looks_expository_topic(txt, m)

    exp_hits        = len(RE_RC_EXP_LIKE.findall(lc))
    strong_exp_hits = len(RE_RC37_STRONG_EXP.findall(lc))
    reasoning_hits  = len(RE_RC37_REASONING_META.findall(lc))
    causal_hits     = len(RE_RC37_CAUSAL_CHAIN.findall(lc))
    example_hits    = len(RE_RC36_EXAMPLE_CUE.findall(lc))
    definition_hits = len(RE_RC36_DEF_CUE.findall(lc))

    # ê°ì • ë³€í™” + (ì—°êµ¬ ì‹ í˜¸ ì—†ìŒ) + (ì„¤ëª…ë¬¸ ì•„ë‹˜) â†’ RC36/37 ë‘˜ ë‹¤ ì œì™¸
    if strong_emotion_shift and not exp_hits and not expository:
        return "none"

    # 1) ê°•í•œ ì‹¤í—˜/ì—°êµ¬ ë³´ê³ í˜•: RC37 ê³ ì •
    #    - ì‹¤í—˜ ì¥ì¹˜/ì°¸ê°€ì/ë¬´ì‘ìœ„ë°°ì • ë“± + ì¼ë°˜ ì—°êµ¬/ë°ì´í„° ì‹ í˜¸ê°€ í•¨ê»˜ ìˆì„ ë•Œ
    if strong_exp_hits >= 1 and exp_hits >= 2:
        return "RC37"

    # 2) ì—°êµ¬ ë‹¨ì–´ëŠ” ì¡°ê¸ˆ ìˆì§€ë§Œ, ì „í˜•ì ì¸ ì •ì˜/ì˜ˆì‹œ ì¤‘ì‹¬ ì„¤ëª…ë¬¸:
    #    - ì—°êµ¬ê°€ 'ì˜ˆì‹œë¡œ ì‚´ì§' ë“±ì¥í•˜ëŠ” RC36 ê¸°ì¶œì„ RC37ë¡œ ë³´ë‚´ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬
    if exp_hits >= 1 and expository and (example_hits + definition_hits) >= 2 and reasoning_hits == 0:
        return "RC36"

    # 3) ë‹¨ê³„ì  ë…¼ì¦ êµ¬ì¡° (ì—°êµ¬ ë‹¨ì–´ ì—†ì–´ë„ RC37ë¡œ ë³´ë‚´ê³  ì‹¶ì€ ê²½ìš°)
    #    - ë…¼ì¦/ëª¨í˜•/ì›ë¦¬ ë©”íƒ€ ë‹¨ì–´ + ì¸ê³¼ ì—°ì‡„ ì‹ í˜¸ê°€ ë™ì‹œì— ìˆì„ ë•Œ
    if expository and reasoning_hits >= 1 and causal_hits >= 1:
        return "RC37"

    # 4) ì „í˜•ì ì¸ ì •ì˜/ì˜ˆì‹œ ì¤‘ì‹¬ ì„¤ëª…ë¬¸ â†’ RC36
    if expository and (example_hits >= 1 or definition_hits >= 1):
        return "RC36"

    # 5) ì„¤ëª…ë¬¸ì´ê¸´ í•œë° ìœ„ ì‹ í˜¸ê°€ ì• ë§¤í•˜ê²Œ ì ë‹¤ë©´:
    #    - ê¸°ì¶œ ë¶„í¬ìƒ RC36ì´ ë” ë§ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ì„ RC36ìœ¼ë¡œ ë‘ 
    if expository:
        return "RC36"

    # 6) ì„¤ëª…ë¬¸ë„ ì•„ë‹ˆê³  ì• ë§¤í•˜ì§€ë§Œ (A)(B)(C) êµ¬ì¡°ëŠ” ì¡íŒ ê²½ìš°:
    #    - ê¸°ë³¸ì€ RC37ë¡œ ë‘ë˜, ì´í›„ add ë‹¨ê³„ì—ì„œ ë‹¤ì‹œ ê±¸ëŸ¬ì§ˆ ìˆ˜ ìˆìŒ
    return "RC37"




def _basic_counts(text: str) -> Dict[str, float]:
    t = (text or "").strip()
    tokens = re.findall(r"[A-Za-z]+(?:['-][A-Za-z]+)?|\d+%?", t)
    tok = len(tokens)
    sent = max(1, len(re.findall(r"[.!?]+(?:\s|$)", t)))
    paras = max(1, t.count("\n\n") + 1)
    lower = [w.lower() for w in tokens if re.match(r"[A-Za-z]", w)]
    uniq = len(set(lower))
    ttr = (uniq / max(1, len(lower))) if lower else 0.0
    dm_cnt = sum(1 for w in lower if w in DISCOURSE_MARKERS)
    deictic_cnt = sum(1 for w in lower if w in DEICTICS)
    digits_cnt = len(re.findall(r"\b\d{2,4}(?:%|[.,]?\d+)?\b", t))
    unit_cnt = len(re.findall(r"\b(?:km|kg|cm|mm|Â°c|Â°f|mph|percent|percentages?)\b", t, re.I))
    proper_like = len(re.findall(r"\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)?\b", t))
    return {
        "tok": tok, "sent": sent, "paras": paras, "ttr": ttr,
        "avg_len": (tok / max(1, sent)),
        "dm_cnt": dm_cnt, "deictic_cnt": deictic_cnt,
        "num_cnt": digits_cnt + unit_cnt, "proper_like": proper_like
    }


def _is_notice_like(txt: str, m: Dict[str, float]) -> bool:
    """
    RC27/RC28 ì•ˆë‚´ë¬¸ í›„ë³´ ì—¬ë¶€ íŒë³„:
    - ì„¹ì…˜ ë¼ë²¨(Deadline, Restrictions, Awards ë“±) + bullet/ê°€ê²©/ê¸°ê°„ ì •ë³´ê°€ ë‹¤ìˆ˜
    - ì§§ì€ ì‚¬ì‹¤ ë¬¸ì¥ ì—¬ëŸ¬ ê°œë¡œ êµ¬ì„±ëœ ê³µì§€/ì•ˆë‚´/ì„œë¹„ìŠ¤ ì†Œê°œë¬¸
    """
    if not txt:
        return False

    t = txt.lower()

    # 1) ê°•í•œ í˜•ì‹ ì‹ í˜¸: ì„¹ì…˜ ë¼ë²¨ or URL
    strong = bool(RE_NOTICE_KEYS.search(txt) or RE_WEBSITE_URL.search(txt))

    # 2) ë³´ì¡° ì‹ í˜¸ë“¤
    bullet_hits = bool(RE_BULLET_DOT.search(txt))
    price_hits = bool(RE_PRICE_SIGN.search(txt))
    date_or_period = bool(
        re.search(
            r"\b(deadline|period|schedule|from\s+\w+\s+\d|\d{1,2}:\d{2}\s*(?:a\.m\.|p\.m\.)|"
            r"tour\s+times?|renovation period|from\s+june|from\s+november)\b",
            t,
        )
    )
    # ì•ˆë‚´ë¬¸ íŠ¹ìœ ì˜ ì„œë¸Œ ì„¹ì…˜ í‚¤ì›Œë“œ
    section_hits = len(
        re.findall(
            r"\b(age requirement|restrictions?|participants?|awards?|evaluation criteria|"
            r"activities?|use|return|service range|purchase information|tour times?|"
            r"renovation period|areas to be closed|card type|additional information)\b",
            t,
        )
    )

    fact_signals = sum(
        [
            1 if bullet_hits else 0,
            1 if price_hits else 0,
            1 if date_or_period else 0,
            1 if section_hits >= 1 else 0,
        ]
    )

    # 3) ë¬¸ì¥ ìˆ˜/ê¸¸ì´ ê¸°ë°˜ í•„í„°
    tok = m.get("tok", 0)
    sent = m.get("sent", 1)

    # - ë¬¸ì¥ 3~4ê°œ ì´ìƒ + ì‚¬ì‹¤ ì‹ í˜¸ 2ê°œ ì´ìƒ
    # - ë„ˆë¬´ ê¸´ ë…¼ì„¤ë¬¸/ì¥ë¬¸ì€ ì œì™¸ (ì„¸íŠ¸/ì„¤ëª…ë¬¸ ê°€ëŠ¥ì„±)
    if (strong and sent >= 3) or (fact_signals >= 2 and sent >= 4 and tok <= 220):
        return True
    return False

def _bump(base: Dict[str, Dict], t: str, v: float):
    if t in base:
        base[t]["fit"] = float(min(1.0, base[t]["fit"] + v))

def _apply_length_based_boosts(base: Dict[str, Dict], m: Dict[str, float]) -> None:
    tok, avg_len, paras = m["tok"], m["avg_len"], m["paras"]
    if tok < 150:
        for t,v in (("RC18",0.06),("RC19",0.04),("RC27",0.05),("RC28", 0.03),("RC24",0.02)):
            _bump(base,t,v)
    elif tok < 190:
        for t,v in (("RC20",0.03),("RC22",0.04),("RC23",0.04),("RC26",0.03),
                    ("RC25",0.03),("RC27",0.02),("RC28",0.02),
                    ("RC29",0.04),("RC30",0.03),("RC36",0.03)):
            _bump(base,t,v)
    else:
        for t,v in (("RC31",0.04),("RC32",0.04),("RC33",0.03),("RC34",0.04),
                    ("RC35",0.03),("RC37",0.03),("RC38",0.03),("RC39",0.03),
                    ("RC40",0.03)):
            _bump(base,t,v)
        if tok >= 220:
            _bump(base, "RC41", 0.04)
            _bump(base, "RC42", 0.04)
    if avg_len >= 18:
        for t,v in (("RC31",0.02),("RC32",0.03),("RC33",0.03),("RC29",0.02)):
            _bump(base,t,v)
    if paras >= 2:
        for t,v in (("RC22",0.03),("RC23",0.03),("RC32",0.02),("RC33",0.02),("RC40",0.03)):
            _bump(base,t,v)
    if paras >= 3 and m["tok"] >= 180:
        for t,v in (("RC41",0.03),("RC42",0.03)):
            _bump(base,t,v)

def _apply_signal_boosts(base: Dict[str, Dict], txt: str, m: Dict[str, float]) -> None:
    # ë‹´í™”í‘œì§€Â·ì§€ì‹œì–´ ê¸°ë°˜ ë³´ì •
    if m["dm_cnt"] >= 4:
        for t,v in (("RC22",0.05),("RC23",0.04),("RC31",0.03),("RC32",0.03),("RC33",0.03),("RC38",0.03),("RC39",0.03)):
            _bump(base,t,v)
    if m["deictic_cnt"] >= 6:
        for t,v in (("RC38",0.04),("RC39",0.04),("RC36",0.03),("RC37",0.03),("RC22",0.02),("RC40",0.02)):
            _bump(base,t,v)
    if RE_RC39_META.search(txt) and RE_RC39_CONTRAST.search(txt):
        _bump(base, "RC39", 0.06)            


    notice_like = _is_notice_like(txt, m)            

        # â˜… RC40: í˜ì–´ë§/ëŒ€ì¡° ì‹ í˜¸ê°€ ëšœë ·í•œ ì„¤ëª…ë¬¸ì— ì¶”ê°€ ê°€ì 
    if not notice_like and not RE_BIO.search(txt):
        if RE_RC40_PAIRING.search(txt):
            _bump(base, "RC40", 0.06)

    # --- RC25: í‘œÂ·ê·¸ë˜í”„/í†µê³„ ê¸°ë°˜ ì§€ë¬¸ ê°•ì‹ í˜¸ ---
    # --- RC25: í‘œÂ·ê·¸ë˜í”„/í†µê³„ ê¸°ë°˜ ì§€ë¬¸ ê°•ì‹ í˜¸ ---
    chart_like = bool(RE_TABLEY.search(txt) or RE_CHARTY.search(txt))
    sent_cnt = m.get("sent", 1)

    # âš  ì„ ì§€ë¡œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ë¬¸ì¥ ìµœì†Œ 5ê°œ í•„ìš”
    if sent_cnt >= 5 and (chart_like or m["num_cnt"] >= 3):
        year_hits = len(re.findall(r"\b\d{4}\b", txt))
        compare_hits = len(re.findall(r"\b(compared to|compared with|than|whereas)\b", txt, re.I))
        group_hits = len(re.findall(
            r"\b(rural|urban|country|countries|region|regions|age group|age-group|age groups|respondents|survey)\b",
            txt,
            re.I,
        ))

        if m["num_cnt"] >= 3:
            _bump(base, "RC25", 0.08)
        if chart_like:
            _bump(base, "RC25", 0.06)
        if year_hits >= 2:
            _bump(base, "RC25", 0.05)
        if compare_hits >= 1:
            _bump(base, "RC25", 0.04)
        if group_hits >= 1:
            _bump(base, "RC25", 0.04)

    if RE_BIO.search(txt):
        _bump(base,"RC26",0.06)
    if m["ttr"] < 0.35:
        for t,v in (("RC31",0.04),("RC40",0.04)):
            _bump(base,t,v)
    if m["proper_like"] >= 6:
        for t,v in (("RC22",0.02),("RC23",0.02),("RC31",0.02),("RC40",0.02)):
            _bump(base,t,v)

    has_letter = bool(RE_LETTER_DEAR.search(txt) or RE_LETTER_CLOSE.search(txt))
    has_intent = bool(
        RE_INTENT_REQUEST.search(txt)
        or RE_INTENT_INQUIRY.search(txt)
        or RE_INTENT_GUIDE.search(txt)
        or RE_INTENT_PROMO.search(txt) 
    )

    if has_letter:
        _bump(base, "RC18", 0.10)

    # intent í‘œí˜„ë§Œ ìˆì–´ë„ RC18 ê°€ì¤‘ì¹˜ ì¶”ê°€
    if has_intent:
        _bump(base, "RC18", 0.06)

    # í¸ì§€ í˜•ì‹ + intentê°€ ë™ì‹œì— ìˆìœ¼ë©´ í•œ ë²ˆ ë” ì†Œí­ ë³´ì •
    if has_letter and has_intent:
        _bump(base, "RC18", 0.04)

    if RE_EMOTION.search(txt):
        _bump(base,"RC19",0.06)
    if RE_ARGUMENT.search(txt):
        _bump(base,"RC20",0.05)

    shell_hit = any(p.search(txt) for p in RE_IDIOM_SHELLS)
    simile_hit = bool(RE_SIMILE.search(txt))
    lc = txt.lower()
    cue_hits = sum(1 for w in METAPHOR_CUES if w in lc)
    if shell_hit or simile_hit or cue_hits >= 1:
        _bump(base,"RC21",0.05)
    if notice_like:
        _bump(base, "RC27", 0.12)
        _bump(base, "RC28", 0.06)

        # ì•ˆë‚´ë¬¸ì—ì„œëŠ” ì„¤ëª…ë¬¸ Evergreen ê³„ì—´ì„ ì•½í•˜ê²Œ ì¤„ì¸ë‹¤.
        for t, delta in (
            ("RC22", -0.12), ("RC23", -0.12), ("RC24", -0.08),
            ("RC31", -0.12), ("RC32", -0.10), ("RC33", -0.10),
            ("RC40", -0.10),
        ):
            if t in base:
                base[t]["fit"] = float(max(0.0, base[t]["fit"] + delta))
    elif RE_NOTICE_KEYS.search(txt) or RE_WEBSITE_URL.search(txt):
        _bump(base,"RC27",0.05)
        _bump(base,"RC28",0.04)
    if RE_GRAMMAR_META.search(txt):
        _bump(base,"RC29",0.04)
    if RE_LEXICAL_META.search(txt):
        _bump(base,"RC30",0.04)
    if RE_NUM_BULLETS.search(txt) and RE_UNDERLINE.search(txt):
        _bump(base,"RC29",0.08); _bump(base,"RC30",0.06)
    if RE_INSERT_PARENS.search(txt):
        _bump(base,"RC35",0.06); _bump(base,"RC38",0.05)
    if RE_PARAGRAPH_LABELS.search(txt):
        _bump(base,"RC36",0.05); _bump(base,"RC37",0.04)
    if RE_LOWER_PARENS.search(txt):
        _bump(base,"RC41",0.05); _bump(base,"RC42",0.05)
    # --- RC23 ê³„ì—´: ì „í˜•ì ì¸ ì„¤ëª…/ë¶„ì„ ì§€ë¬¸ì—ì„œ ì£¼ì œ/ì œëª©/ìš”ì§€ ê°€ì¤‘ì¹˜ ---
    if _looks_expository_topic(txt, m):
        # ì œëª© ì¶”ë¡ ì„ ëŒ€í‘œ ìœ í˜•ìœ¼ë¡œ ì•½ê°„ ë” ë†’ê²Œ
        _bump(base, "RC24", 0.10)  # ì œëª© ì¶”ë¡ 
        _bump(base, "RC23", 0.06)  # ì£¼ì œ íŒŒì•…
        _bump(base, "RC22", 0.04)  # ìš”ì§€ íŒŒì•…

def _apply_final_table_boosts(merged: Dict[str, Dict], passage: str) -> None:
    metrics = _basic_counts(passage or "")
    _apply_length_based_boosts(merged, metrics)
    _apply_signal_boosts(merged, passage or "", metrics)

# ---------- Public API ----------
def rule_based_candidates(passage: str) -> List[Dict]:
    cands: List[Dict] = []
    txt = sanitize_user_passage(passage or "")
    tokens = len(txt.split())
    band = _length_band(tokens)
    allowed_types = ALLOW_BY_LENGTH.get(band, ALLOW_BY_LENGTH["upto_rc33"])

    # emotion-shift íŒì •ìš© (RC19 ê°•ì‹ í˜¸)
    lc = txt.lower()
    neg_hits = sum(1 for w in NEG_EMO if w in lc)
    pos_hits = sum(1 for w in POS_EMO if w in lc)
    has_turning = bool(RE_TURNING.search(txt))
    strong_emotion_shift = (
        (neg_hits > 0 and pos_hits > 0) or
        (has_turning and RE_EMOTION.search(txt))
    )

    metrics = _basic_counts(txt)
    notice_like = _is_notice_like(txt, metrics)

    def add(t: str, fit: float, reason: str, hint: str = "-"):
        if t not in allowed_types:
            return
        cands.append({
            "type": t,
            "fit": float(max(0.0, min(1.0, fit))),
            "reason": reason[:120],
            "prep_hint": hint,
        })
    # ê³µì§€/ì•ˆë‚´ë¬¸: RC27 ìµœìš°ì„ , RC28 ë³´ì¡°
    if notice_like:
        add(
            "RC27",
            0.90,
            "ê³µì§€/ì•ˆë‚´ë¬¸: ë‹¤ìˆ˜ì˜ ì‚¬ì‹¤Â·ì¡°ê±´Â·ê¸°ê°„Â·ìš”ê¸ˆ ì •ë³´ ë‚˜ì—´",
            "í‘œÂ·ì¡°ê±´ì„ ê·¸ëŒ€ë¡œ ì„ ì§€ë¡œ ì˜®ê²¨ ì‚¬ì‹¤ ì—¬ë¶€ íŒë‹¨"
        )
        add(
            "RC28",
            0.80,  # â˜… 0.72 â†’ 0.80 ì •ë„ë¡œ ìƒí–¥
            "ê³µì§€/ì•ˆë‚´ë¬¸: ì¼ë¶€ ì ì ˆí•œ ë‚´ìš© ì„ íƒ ê°€ëŠ¥",
            "ì „ì²´ ì•ˆë‚´ì™€ ì–´ìš¸ë¦¬ëŠ” ë‚´ìš© 1ê°œë§Œ ê³ ë¥´ê¸°"
        )
    elif RE_NOTICE_KEYS.search(txt):
        add("RC27", 0.85, "ê³µì§€/ì•ˆë‚´ë¬¸ ì„¹ì…˜ í‚¤ ê²€ì¶œ", "ì„¹ì…˜ ìœ ì§€, ì‚¬ì‹¤ ê²€ì¦ í¬ì¸íŠ¸ í‘œì‹œ")
        add("RC28", 0.80, "ê³µì§€/ì•ˆë‚´ë¬¸ ì„¹ì…˜ í‚¤ ê²€ì¶œ", "ì •í•© ì‚¬ì‹¤ 1ê°œë§Œ ë§ê²Œ ì˜µì…˜ êµ¬ì„±")

    if RE_INSERT_PARENS.search(txt):
        add("RC38", 0.90, "( â‘  )~( â‘¤ ) ì‚½ì… í¬ì¸íŠ¸ íŒ¨í„´", "ë‹´í™”í‘œì§€/ì§€ì‹œì–´ ì—°ê²°ì„± ê²€ì‚¬")
        add("RC39", 0.85, "( â‘  )~( â‘¤ ) ì‚½ì… í¬ì¸íŠ¸ íŒ¨í„´(ê³ ë‚œë„)", "ì „í›„ ë…¼ë¦¬ ì‹¬ì¸µ ì ê²€")

    if RE_NUM_BULLETS.search(txt) and RE_UNDERLINE.search(txt):
        rc29_ok = _llm_rc29_feasible(txt)
        add("RC29",
            0.88 if rc29_ok else 0.50,
            "â‘ ~â‘¤ + <u>â€¦</u> íŒ¨í„´" + (" (ì‚¬ì „íŒì •: ê°€ëŠ¥)" if rc29_ok else " (ì‚¬ì „íŒì •: ë¶ˆí™•ì‹¤)"),
            "ë¬¸ë²•/êµ¬ë¬¸ ì˜¤ë¥˜ 1ê°œ íƒì§€")
        add("RC30", 0.80, "â‘ ~â‘¤ + <u>â€¦</u> íŒ¨í„´", "ì–´íœ˜/ì½œë¡œì¼€ì´ì…˜ ë¶€ì ì ˆ 1ê°œ íƒì§€")

    if RE_NUM_BULLETS.search(txt) and not RE_UNDERLINE.search(txt):
        rc29_ok = _llm_rc29_feasible(txt)
        if rc29_ok:
            add("RC29", 0.70, "â‘ ~â‘¤ ë²ˆí˜¸ë§Œ ê°ì§€: ë¬¸ë²• íŒë‹¨ ê¸°ë³¸í˜• (ì‚¬ì „íŒì •: ê°€ëŠ¥)", "ìˆ˜ì¼ì¹˜/ì‹œì œ/ê´€ê³„ì‚¬/ì¤€ë™ì‚¬ ì ê²€")
        else:
            add("RC29", 0.45, "â‘ ~â‘¤ ë²ˆí˜¸ë§Œ ê°ì§€ (ì‚¬ì „íŒì •: ë¶ˆí™•ì‹¤)", "ìˆ˜ì¼ì¹˜/ì‹œì œ/ê´€ê³„ì‚¬/ì¤€ë™ì‚¬ ì ê²€")

    try:
        has_bullets = bool(RE_NUM_BULLETS.search(txt))
        has_insert_mark = bool(RE_INSERT_PARENS.search(txt))
        has_underline = bool(RE_UNDERLINE.search(txt))

        # 1) LLM íŒ¨ìŠ¤ìŠ¤ë£¨ìš© RC21 (ê¸°ì¡´ ë¡œì§ ìœ ì§€, ì¡°ê±´ì€ ê·¸ëŒ€ë¡œ)
        if FORCE_RC21_PASS and not has_bullets and not has_insert_mark:
            add(
                "RC21",
                0.55,
                "íŒ¨ìŠ¤ìŠ¤ë£¨: LLM ê²€ì¦ìš© í›„ë³´(í˜•ì‹ ì‹ í˜¸ ì•½í•¨)",
                "ë¬¸ë§¥ ì† í‘œí˜„ì˜ ì˜ë¯¸ë¥¼ ì¶”ë¡ í•˜ëŠ” ì—°ìŠµ",
            )

        # 2) ì˜ë¯¸/ë¹„ìœ  ê¸°ë°˜ RC21 ìŠ¤ì½”ì–´ë§ (â˜… í˜•ì‹ì´ ìˆì–´ë„ í‰ê°€)
        rc21_score = _score_rc21_semantic(
            txt,
            has_bullets=has_bullets,
            has_underline=has_underline,
            has_insert_mark=has_insert_mark,
        )

        if rc21_score >= 0.60:
            # ê°•í•œ ë¹„ìœ /ê´€ìš© ì‹ í˜¸
            fit = 0.78 if not (has_bullets or has_underline or has_insert_mark) else 0.70
            add(
                "RC21",
                fit,
                "ê´€ìš©/ë¹„ìœ  í‘œí˜„ ê°•í•œ ì‹ í˜¸ ê°ì§€",
                "í•µì‹¬ ë¹„ìœ /ê´€ìš© í‘œí˜„ì´ ë¬¸ë§¥ì—ì„œ ë¬´ì—‡ì„ ëœ»í•˜ëŠ”ì§€ ì„¤ëª…í•´ ë³´ê¸°",
            )
        elif rc21_score >= 0.45:
            # ì¤‘ê°„ ì •ë„ì˜ ë¹„ìœ /ê´€ìš© ì‹ í˜¸
            fit = 0.68 if not (has_bullets or has_underline or has_insert_mark) else 0.60
            add(
                "RC21",
                fit,
                "ê´€ìš©/ë¹„ìœ  í‘œí˜„ ì‹ í˜¸ ê°ì§€",
                "ë¬¸ì¥ ì „ì²´ ì˜ë¯¸ ì†ì—ì„œ í‘œí˜„ì´ ë§¡ëŠ” ì—­í• ì„ ì •ë¦¬í•˜ëŠ” ì—°ìŠµ",
            )

    except Exception:
        pass

    if RE_CIRCLED.search(txt) and RE_INLINE_LEX.search(txt):
        add("RC30", 0.65, "â‘ ~â‘¤ ë’¤ ë‹¨ì¼/ì§§ì€ ì–´íœ˜ í›„ë³´", "ë¬¸ë§¥/ì½œë¡œì¼€ì´ì…˜ ë¶ˆì¼ì¹˜ íƒì§€")

    sem30 = _score_rc30_semantic(txt)
    if sem30 >= 0.35:
        add("RC30", sem30, "í˜•ì‹ ì—†ì´ ì–´íœ˜Â·ë‰˜ì•™ìŠ¤Â·ì½œë¡œì¼€ì´ì…˜ ë‹¨ì„œ", "ë¬¸ë§¥ìƒ ì–´íœ˜ ì í•©ì„± ì ê²€")
        
    sem29 = _score_rc29_semantic(txt)
    if sem29 >= 0.30:
        add("RC29", sem29, "í˜•ì‹ ì—†ì´ ë¬¸ë²• ë©”íƒ€ ë‹¨ì„œ", "ì‹œì œ/ìˆ˜ì¼ì¹˜/ì „ì¹˜ì‚¬/ê´€ì‚¬ ë“± ì ê²€")

    struct29 = _score_rc29_structure(txt)
    if struct29 >= 0.35 and "RC29" in allowed_types:
        if (not notice_like) and (not RE_BIO.search(txt)) and (not strong_emotion_shift):
            rc29_ok = False
            if 80 <= tokens <= 220:
                rc29_ok = _llm_rc29_feasible(txt)

            if rc29_ok:
                fit = max(struct29, 0.62)
                reason = "í˜•ì‹ ì‹ í˜¸ ì—†ì´ë„ ë¬¸ì¥ êµ¬ì¡°ë§Œìœ¼ë¡œ RC29(ì–´ë²• íŒë‹¨) ì¶œì œê°€ ê°€ëŠ¥(LLM ì‚¬ì „íŒì •: ê°€ëŠ¥)"
            else:
                fit = struct29
                reason = "í˜•ì‹ ì‹ í˜¸ëŠ” ì—†ì§€ë§Œ, ê´€ê³„ì‚¬/ì¢…ì†ì ˆ ë“± ë¬¸ë²• í¬ì¸íŠ¸ê°€ ë§ì€ ì„¤ëª…ë¬¸"

            add(
                "RC29",
                fit,
                reason,
                "ê´€ê³„ì‚¬, ìˆ˜ì¼ì¹˜, ì‹œì œ, ë¶„ì‚¬êµ¬ ë“± ë¬¸ë²• í¬ì¸íŠ¸ 5ê³³ì„ ê³¨ë¼ 1ê³³ë§Œ í‹€ë¦¬ê²Œ ë§Œë“œëŠ” ì—°ìŠµ",
            )

    sent_cnt = max(1, len(re.findall(r"[.!?]+(?:\s|$)", txt)))
    if (RE_CHARTY.search(txt) or RE_TABLEY.search(txt)) and sent_cnt >= 5:
        add(
            "RC25",
            0.78,
            "í‘œÂ·ê·¸ë˜í”„/í†µê³„ ìˆ˜ì¹˜ë¥¼ ì„¤ëª…í•˜ëŠ” ì§€ë¬¸(ë¬¸ì¥ 5ê°œ ì´ìƒ)",
            "ì§€ë¬¸ ì† ë¬¸ì¥ 5ê°œë¥¼ ê·¸ëŒ€ë¡œ ì„ ì§€ë¡œ ì¨ì„œ ì‚¬ì‹¤ íŒë‹¨ ì—°ìŠµ"
        )

    # --- RC26: ì „ê¸°í˜•(ê°œì¸ ìƒì• ) ì§€ë¬¸ë§Œ ê°•í•˜ê²Œ ì¶”ì²œ ---
    if RE_BIO.search(txt):
        # ì²« ë¬¸ì¥ ê¸°ì¤€ìœ¼ë¡œ 'ì§‘ë‹¨/ë¯¼ì¡±/ë¬¸í™” ì„¤ëª…ë¬¸'ì¸ì§€ ê°€ë³ê²Œ í•„í„°
        first_sent = re.split(r"[.!?]", txt, 1)[0]
        is_group_like = bool(re.search(
            r"\b(ethnic group|people|tribe|nation|society|community|culture)\b",
            first_sent,
            re.I,
        ))

        # ì¸ì¹­ëŒ€ëª…ì‚¬(he/she/his/her) ë˜ëŠ” ê³ ìœ ëª…ì‚¬(ì¸ëª…) ë‹¤ìˆ˜ + ì—°ë„ ì •ë³´ê°€ ìˆìœ¼ë©´ ê°œì¸ ì „ê¸°ë¡œ ë³¸ë‹¤.
        pron_hits = len(re.findall(r"\b(he|she|his|her)\b", txt, re.I))
        year_hits = len(re.findall(r"\b(18|19|20)\d{2}\b", txt))
        metrics = _basic_counts(txt)
        proper_hits = metrics.get("proper_like", 0)

        if (not is_group_like) and year_hits >= 1 and (pron_hits >= 1 or proper_hits >= 2):
            # âœ… ì „í˜•ì ì¸ 'ê°œì¸ ì „ê¸°'ë¡œ íŒì •ë˜ëŠ” ê²½ìš°ì—ë§Œ RC26ì„ ê°•í•˜ê²Œ ì¶”ê°€
            add(
                "RC26",
                0.82,  # ì´ì „ 0.76 â†’ ì•½ê°„ ìƒí–¥
                "ê°œì¸ ì „ê¸°: ì¶œìƒÂ·ê²½ë ¥Â·ì—°ëŒ€ê¸°ì  ì‚¬ê±´ ë‚˜ì—´",
                "ì—°ëŒ€í‘œÂ·ìƒì•  ì‚¬ê±´ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë¦¬í•˜ëŠ” ì—°ìŠµ"
            )
        # else:
        #   - RE_BIOëŠ” ì¡í˜”ìœ¼ë‚˜ ì§‘ë‹¨/ë¬¸í™” ì„¤ëª…ì— ê°€ê¹ê±°ë‚˜ ì—°ëŒ€ê¸°/ê°œì¸ì„±ì´ ì•½í•œ ê²½ìš°
        #   - RC26ì€ ê·œì¹™ ê¸°ë°˜ì—ì„œëŠ” ì¶”ê°€í•˜ì§€ ì•Šê³ , LLM ìª½ì—ì„œë§Œ (ìˆë‹¤ë©´) ì•½í•˜ê²Œ ì‘ë™
    if "RC35" in allowed_types:
        if _looks_rc35_expository_flow(txt, metrics, strong_emotion_shift):
            add(
                "RC35",
                0.72,  # ì¤‘ê°„ ì´ìƒ fit: í•­ìƒ í›„ë³´ì— ë³´ì´ë„ë¡
                "5ë¬¸ì¥ ì´ìƒ ë‹¨ì¼ ì£¼ì œ ì„¤ëª…ë¬¸: RC35(ë¬´ê´€í•œ ë¬¸ì¥ ì°¾ê¸°) ì¶œì œ ê°€ëŠ¥",
                "ì—¬ëŸ¬ ë¬¸ì¥ ì¤‘ ì „ì²´ íë¦„ê³¼ ê°€ì¥ ì–´ìš¸ë¦¬ì§€ ì•ŠëŠ” ë¬¸ì¥ì„ ê³ ë¥´ëŠ” ì—°ìŠµ",
            )

    if RE_ARGUMENT.search(txt):
        add("RC20", 0.70, "ë‹¹ìœ„/ê¶Œê³  í‘œí˜„ ê°ì§€", "ì£¼ì¥Â·ê·¼ê±°Â·ë°˜ë¡  êµ¬ì¡°")

    #  RC19 â€“ ê°ì • ë‹¨ì–´ë§Œ ìˆì„ ë•Œ vs ëª…í™•í•œ ì‹¬ê²½ ë³€í™”ì¼ ë•Œ êµ¬ë¶„
    if RE_EMOTION.search(txt):
        if strong_emotion_shift:
            add(
                "RC19",
                0.80,
                "ë¶€ì •/ê¸ì • ê°ì • + ì „í™˜ í‘œí˜„ì´ í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ” ì„œì‚¬ë¬¸",
                "ì´ˆê¸°Â·ì „í™˜Â·ìµœì¢… ì •ì„œë¥¼ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë¦¬",
            )
        else:
            add(
                "RC19",
                0.60,
                "ì •ì„œ ì–´íœ˜ ê°ì§€",
                "ì´ˆê¸°Â·ì „í™˜Â·ìµœì¢… ì •ì„œë¥¼ êµ¬ë¶„í•´ ë³´ëŠ” ì—°ìŠµ",
            )

    abc_class = _classify_abc_for_rc36_37(txt, metrics, strong_emotion_shift)

    if abc_class == "RC36":
        add(
            "RC36",
            0.72,
            "(A)(B)(C) ë¼ë²¨ + ì„¤ëª…ë¬¸ êµ¬ì¡°: RC36(ë‹¨ë½ ìˆœì„œ ë°°ì—´) ì í•©",
            "ë‹´í™”í‘œì§€/ì§€ì‹œì–´ë¥¼ ì´ìš©í•´ (A)(B)(C)ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ìˆœì„œë¥¼ ì¶”ë¡ ",
        )
    elif abc_class == "RC37":
        add(
            "RC37",
            0.72,
            "(A)(B)(C) ë¼ë²¨ + ì—°êµ¬/ì‹¤í—˜ ë˜ëŠ” ë¹„ì •í˜• êµ¬ì¡°: RC37 ì í•©",
            "ê°€ì„¤-ë°©ë²•-ê²°ê³¼/ì¡°ê±´ë³„ ê²°ê³¼Â·í•´ì„ êµ¬ì¡°ë¥¼ íŒŒì•…í•´ ë¬¸ì¥ ìœ„ì¹˜Â·ì—­í• ì„ ì¶”ë¡ ",
        )
    # "none"ì´ë©´ RC36/RC37 ë‘˜ ë‹¤ ì¶”ì²œí•˜ì§€ ì•ŠìŒ
   # --- NEW: 'ê¹¨ë—í•œ' ì„¤ëª…ë¬¸ì—ì„œì˜ RC38(ë¬¸ì¥ ì‚½ì…) í›„ë³´ ---

   # --- NEW: 'ê¹¨ë—í•œ' ì„¤ëª…ë¬¸ì—ì„œì˜ RC38(ë¬¸ì¥ ì‚½ì…) í›„ë³´ ---
    if "RC38" in allowed_types and not RE_INSERT_PARENS.search(txt):
       if _looks_rc38_insertion_friendly(txt, metrics, strong_emotion_shift, notice_like):
           add(
               "RC38",
               0.72,
               "ì‚½ì…í‘œì‹œê°€ ì—†ì§€ë§Œ ì „í™˜/pivot ë¬¸ì¥ì´ ìˆëŠ” ì„¤ëª…ë¬¸: RC38(ë¬¸ì¥ ì‚½ì…) ì¶œì œ ê°€ëŠ¥",
               "ì¤‘ê°„ì˜ ì „í™˜ ë¬¸ì¥ì´ ì–´ëŠ ìœ„ì¹˜ì— ë“¤ì–´ê°€ì•¼ ê¸€ íë¦„ì´ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ì§€ íŒë‹¨í•˜ëŠ” ì—°ìŠµ",
           )
 
    # --- NEW: 'ê¹¨ë—í•œ' ë…¼ì¦/ë¹„ìœ  ì§€ë¬¸ì—ì„œì˜ RC39(ê³ ë‚œë„ ë¬¸ì¥ ì‚½ì…) í›„ë³´ ---
    if "RC39" in allowed_types and not RE_INSERT_PARENS.search(txt):
        if _looks_rc39_argument_insertion(txt, metrics, strong_emotion_shift, notice_like):
            add(
                "RC39",
                0.74,
                "ë¹„ìœ /ë…¼ì¦ ì „ê°œ ì¤‘ê°„ì— meta ë¬¸ì¥ì´ ë“¤ì–´ê°€ëŠ” ì‚½ì…í˜•: RC39(ê³ ë‚œë„ ë¬¸ì¥ ì‚½ì…) ì¶œì œ ê°€ëŠ¥",
                "ì–´ë””ì—ì„œ ë…¼ì¦ì˜ ë°©í–¥ì´ ë°”ë€Œê±°ë‚˜ ë¹„ìœ Â·ë¹„êµê°€ ê¹¨ì§€ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ì—°ìŠµ",
            )


    if RE_LOWER_PARENS.search(txt):
        add("RC41", 0.72, "(a)(b)(c) ì†Œë¬¸ì ë¼ë²¨ ê°ì§€: ì„¸íŠ¸í˜• ì í•©", "ë¬¸ë‹¨ë³„ í•µì‹¬Â·ì—°ê²°ê´€ê³„ íŒŒì•…")
        add("RC42", 0.70, "(a)(b)(c) ì†Œë¬¸ì ë¼ë²¨ ê°ì§€: ì„¸íŠ¸í˜•(ê³ ë‚œë„)", "ì„¸ë¶€ ì¶”ë¡ Â·ìƒì„¸ ëŒ€ì¡°")

    set_scores = _score_set_signals(txt)
    if "RC41" in allowed_types and set_scores["rc41"] > 0.0:
        add("RC41", 0.60 + set_scores["rc41"], "(a)(b)(c)/Part/Section/ì°¸ì¡° í‘œì§€: ì„¸íŠ¸í˜•(1)", "ë¬¸ë‹¨ê°„ ê´€ê³„Â·í•µì‹¬ íŒŒì•…")
    if "RC42" in allowed_types and set_scores["rc42"] > 0.0:
        add("RC42", 0.58 + set_scores["rc42"], "(a)(b)(c)/Part/Section/ì°¸ì¡° í‘œì§€: ì„¸íŠ¸í˜•(2)", "ì„¸ë¶€ ì¶”ë¡ Â·ëŒ€ì¡°/ë¹„êµ")

    if tokens >= 90 and not (RE_NOTICE_KEYS.search(txt) or RE_BIO.search(txt)) and not strong_emotion_shift:
        # ì„¤ëª…/ë¶„ì„ ë‹´í™”: ì œëª©/ì£¼ì œ/ìš”ì§€ + ë¹ˆì¹¸/ìš”ì•½ ê³„ì—´
        add("RC24", 0.86, "ì„¤ëª…/ë¶„ì„ ë‹´í™”: ì œëª© ì¶”ë¡ ", "ì „ì²´ íë¦„ì„ í•œ ë¬¸êµ¬ë¡œ ì••ì¶•í•´ ë³´ëŠ” ì—°ìŠµ")
        add("RC23", 0.84, "ì„¤ëª…/ë¶„ì„ ë‹´í™”: ì£¼ì œ íŒŒì•…", "ê¸€ì´ ì„¤ëª…í•˜ëŠ” í•µì‹¬ ê°œë…ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬")
        add("RC22", 0.80, "ì„¤ëª…/ë¶„ì„ ë‹´í™”: ìš”ì§€ íŒŒì•…", "í•„ìì˜ ì „ì²´ ì£¼ì¥Â·ë©”ì‹œì§€ë¥¼ ì •ë¦¬")

        # âœ… RC31ì€ 'í•µì‹¬ ê°œë… ë‹¨ì–´ ë¹ˆì¹¸'ì„ ë„£ê¸° ì¢‹ì€ ì„¤ëª…ë¬¸ì—ì„œë§Œ ì£¼ì…
        if _looks_rc31_blank_friendly(txt, metrics):
            add("RC31", 0.84, "í•µì‹¬ ê°œë… ë‹¨ì–´ ë¹ˆì¹¸ ì í•©", "í•µì‹¬ ëª…ì‚¬êµ¬ ìœ„ì¹˜ì— '_____'")

        add("RC32", 0.78, "êµ¬/ì ˆ ìˆ˜ì¤€ ë¹ˆì¹¸ ì¶”ë¡  ê°€ëŠ¥", "ì›ì¸-ê²°ê³¼/ì „í™˜ ì§€ì  ê³µë°±")
        rc33_fit = 0.74
        if _looks_rc33_high_level(txt, metrics):
            rc33_fit = 0.84  # ê¸°ì¶œ RC33 ì „í˜• íŒ¨í„´ì´ë©´ ì¢€ ë” ê°•í•˜ê²Œ
        add("RC33", rc33_fit, "ê³ ë‚œë„ êµ¬/ì ˆ ë¹ˆì¹¸", "ìš”ì•½/ì „í™˜ ì ˆ ìˆ˜ì¤€")
        rc34_fit = 0.0
        if _looks_rc34_global_blank(txt, metrics):
            # ì „í˜•ì ì¸ RC34 íŒ¨í„´: ì¥ë¬¸ + pivot ì—°ê²°ë¶€ê°€ ëšœë ·í•œ ê²½ìš°
            rc34_fit = 0.86 if tokens >= 170 else 0.83
        elif tokens >= 150:
            # ê¸¸ì´Â·êµ¬ì¡°ëŠ” ì¶©ë¶„íˆ RC34 í›„ë³´ì§€ë§Œ, íŒ¨í„´ ë§¤ì¹­ì´ ì•½í•œ ê²½ìš°(ë³´í†µ ë‚œë„)
            rc34_fit = 0.78

        if rc34_fit > 0.0:
            add(
                "RC34",
                rc34_fit,
                "ì¥ë¬¸ ì„¤ëª…ë¬¸: ê¸€ íë¦„ì„ ë°”ê¾¸ê±°ë‚˜ ì¸ê³¼ë¥¼ ì‡ëŠ” êµ¬/ì ˆì— ê³ ë‚œë„ ë¹ˆì¹¸ ê°€ëŠ¥",
                "ì²«Â·ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ì œì™¸í•œ ì¤‘ê°„ë¶€ ì „í™˜Â·ì¸ê³¼ ì—°ê²° ì ˆ/êµ¬ë¥¼ ë¹ˆì¹¸ìœ¼ë¡œ ìƒê°í•´ ë³´ê¸°",
            )

        # â˜… RC40: 'ë‘ ì¸¡ë©´ìœ¼ë¡œ ìš”ì•½ ê°€ëŠ¥í•œ' ì„¤ëª…ë¬¸ì´ë©´ ë” ê°•í•˜ê²Œ ì¶”ì²œ
        rc40_fit = 0.72
        if _looks_rc40_ab_summary(txt, metrics):
            rc40_fit = 0.86 if tokens >= 150 else 0.83
        add(
            "RC40",
            rc40_fit,
            "í•µì‹¬ ê°œë…ì„ (A)(B) ë‘ ëª…ì‚¬êµ¬ë¡œ ì••ì¶• ê°€ëŠ¥í•œ ì„¤ëª…ë¬¸",
            "(A)(B)ì— ë“¤ì–´ê°ˆ ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´(ë¬¸ì œ/í•´ê²°, í•œê³„/ë³´ì™„, ì›ì¸/ê²°ê³¼ ë“±)ì„ ì°¾ì•„ë³´ê¸°",
        )

    if tokens >= 220:
        add("RC41", 0.62, "ì„¤ëª…ë¬¸: ì„¸íŠ¸í˜•(1) í›„ë³´(ì¥ë¬¸ ì¡°ê±´ ì¶©ì¡±)", "-")
        add("RC42", 0.60, "ì„¤ëª…ë¬¸: ì„¸íŠ¸í˜•(2) í›„ë³´(ì¥ë¬¸ ì¡°ê±´ ì¶©ì¡±)", "-")

    # RC18: í¸ì§€/ë©”ì¼/ê³µì§€ + ëª©ì  í‘œí˜„ ê¸°ë°˜ í›„ë³´ ì¶”ê°€
    has_letter = bool(RE_LETTER_DEAR.search(txt) or RE_LETTER_CLOSE.search(txt))
    has_intent = bool(
        RE_INTENT_REQUEST.search(txt)
        or RE_INTENT_INQUIRY.search(txt)
        or RE_INTENT_GUIDE.search(txt)
        or RE_INTENT_PROMO.search(txt)
    )

    if has_letter:
        base_fit = 0.85 if has_intent else 0.80
        reason = "ì„œì‹  í¬ë§· + ëª©ì /ìš”ì²­ì´ ë¶„ëª…í•œ ì§€ë¬¸" if has_intent else "ì„œì‹  í¬ë§· ê°ì§€"
        hint = "í¸ì§€Â·ì´ë©”ì¼ì—ì„œ ì‘ì„± ì˜ë„ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"
        add("RC18", base_fit, reason, hint)
    else:
        # í¸ì§€ í˜•ì‹ì€ ì•„ë‹ˆì§€ë§Œ, ì§§ì€ ê³µì§€/ì•ˆë‚´ + ëª…í™•í•œ ëª©ì ì¼ ë•Œë„ RC18 í›„ë³´ë¡œ í¬í•¨
        if has_intent and tokens <= 120 and not (RE_CHARTY.search(txt) or RE_TABLEY.search(txt)):
            add(
                "RC18",
                0.70,
                "ê³µì§€/ì•ˆë‚´ë¬¸ì—ì„œ ì°¸ì—¬Â·ë¬¸ì˜ ëª©ì ì´ ë¶„ëª…í•œ ì§€ë¬¸",
                "ë¬¸ì„œì˜ ì „ì²´ ëª©ì ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬",
            )

    cands = _inject_evergreen_candidates(cands, txt, allowed_types)

    merged: Dict[str, Dict] = {}
    for c in cands:
        t = c["type"]
        if t not in merged or c["fit"] > merged[t]["fit"]:
            merged[t] = c

    _apply_final_table_boosts(merged, txt)

    for t in list(merged.keys()):
        if t not in allowed_types:
            merged.pop(t, None)

    cands = sorted(merged.values(), key=lambda x: x["fit"], reverse=True)
    cands = _collapse_set_groups(cands)
    return cands[:12]
