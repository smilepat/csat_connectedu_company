# app/services/item_pipeline.py
from __future__ import annotations

from typing import List, Dict, Any, Optional, Tuple
import random
import os
import json

from app.services.llm_client import call_llm_json
from app.services.validators import validate_with_model
from app.services.postprocess import sanitize_html
from app.specs.registry import get_spec
from app.specs.helpers import make_prompt_with_passage, default_system_prompt
from app.prompts.type_mapping import resolve_item_id_from_type
from app.prompts.prompt_data import ITEM_PROMPTS
from app.specs.passage_preprocessor import retarget_for_item


# -----------------------------
# Small helpers (debug-friendly)
# -----------------------------
def _clip(s: str, n: int = 2000) -> str:
    try:
        return s if len(s) <= n else (s[:n] + "...<clipped>")
    except Exception:
        return str(s)

def _pp_json(obj: Any, n: int = 2000) -> str:
    try:
        return _clip(json.dumps(obj, ensure_ascii=False, indent=2), n)
    except Exception:
        return _clip(str(obj), n)


# -----------------------------
# Router / system prompt helpers
# -----------------------------
DEFAULT_SYSTEM_PROMPT = (
    "You are a routing assistant for CSAT Reading item types. "
    "Your ONLY job is to analyze the given passage and propose suitable item types with confidence scores. "
    "Use ONLY the provided passage. Do NOT invent, alter, or substitute any passage content. "

    "OUTPUT RULES (must follow all): "
    "- Return JSON ONLY. No markdown, no code fences, no commentary. "
    "- JSON shape: { \"candidates\": [ "
    "{\"type\": \"<RC_CODE>\", \"fit\": <float 0..1>, \"reason\": \"<=120 chars\", \"prep_hint\": \"<string or '-'>\" }, ... ] } "
    "- \"type\" must be one of: "
    "[\"RC18\",\"RC19\",\"RC20\",\"RC21\",\"RC22\",\"RC23\",\"RC24\",\"RC25\",\"RC26\",\"RC27\",\"RC28\","
    "\"RC29\",\"RC30\",\"RC31\",\"RC32\",\"RC33\",\"RC36\",\"RC37\",\"RC38\",\"RC39\",\"RC40\","
    "\"RC41\",\"RC42\",\"RC43\",\"RC44\",\"RC45\"]. "
    "- Produce 5â€“10 unique candidates, sorted by \"fit\" descending. "
    "- \"fit\" is confidence in [0,1]; use at most 2 decimals. Lower fit (0.3â€“0.6) is allowed if only content suggests possibility. "
    "- \"reason\": concise rationale (<=120 chars). No line breaks or internal quotes. "
    "- \"prep_hint\": brief solving strategy, or '-' if none. "
    "- No extra keys, no trailing commas, no NaN/Infinity. "

    "SCORING GUIDANCE (for reasoning only, not output): "
    "Expository/explanatory passages â†’ RC22/RC23/RC24/RC31/RC32/RC33/RC40. "
    "Tables/figures/stats (%/ratio/rank) â†’ RC25. "
    "Biographical/timeline (born/awarded/career) â†’ RC26. "
    "Notices/forms (Title:/Date:/Location:) â†’ RC27/RC28. "
    "Letter format (Dear, Sincerely/Regards) â†’ RC18. "
    "Attitude/emotion (feel, anxious, excited, etc.) â†’ RC19. "
    "Claims/obligation (should/must/need to) â†’ RC20. "
    "Labeled chunks (A)(B)(C) â†’ RC36/RC37 (ordering). Even if explicit markers are missing, "
    "if the passage clearly describes a sequence or process, consider RC36/RC37 with lower fit (0.4â€“0.6). "
    "Insertion markers (â‘ ~â‘¤) â†’ RC38/RC39. "
    "Bullets â‘ ~â‘¤ with underlines â†’ RC29/RC30 (grammar/lexis). "

    "HARD CONSTRAINTS: "
    "No explanations outside JSON. Never output text other than the JSON object. "
    "If uncertain, still return best-effort candidates with lower fit."
)

def _get_system_prompt(spec, passage: Optional[str] = None) -> str:
    """
    - spec.system_prompt() ë˜ëŠ” ë¬¸ìì—´ ì œê³µ ì‹œ ìš°ì„  ì‚¬ìš©
    - ì—†ìœ¼ë©´ default_system_prompt() ì‚¬ìš©
    - passageê°€ ìˆìœ¼ë©´ 'ì œê³µëœ ì§€ë¬¸ë§Œ ì‚¬ìš©' ì œì•½ ë¬¸êµ¬ê°€ ì—†ì„ ë•Œ ë³´ê°•
    """
    sp = getattr(spec, "system_prompt", None)
    if callable(sp):
        base = sp()
    elif isinstance(sp, str):
        base = sp
    else:
        base = default_system_prompt()

    if passage:
        guard = "Use ONLY the provided passage. Do NOT invent or substitute a new passage."
        if guard not in base:
            base = (base.rstrip() + "\n" + guard).strip()
    return base


# -----------------------------
# Prompt & pipeline helpers
# -----------------------------
def build_ctx_for_custom(item_id: str, passage: str, difficulty: Optional[str], topic: str) -> Dict[str, Any]:
    """
    ì „ì²˜ë¦¬/ë¦¬íƒ€ê¹ƒíŒ…(erase ëª¨ë“œ ê¸°ë³¸). í•„ìš” ì‹œ fill_copy/fill_ruleë¡œ í™•ì¥ ê°€ëŠ¥.
    â€» ì¸ìš©(quote) ì „ìš© ê²½ë¡œì—ì„œë§Œ ì‚¬ìš©ë¨.
    """
    prepped = retarget_for_item(item_id, passage, fill_mode="erase")
    return {
        "mode": "custom_passage",
        "item_id": item_id,
        "passage": prepped,
        "difficulty": difficulty or "medium",
        "topic": topic or "random",
    }

def _build_prompt_compat(
    spec,
    passage: str,
    *,
    item_id: str,
    difficulty: Optional[str],
    topic: str = "random"
) -> str:
    """
    spec êµ¬í˜„ì²´ ê°„ ì‹œê·¸ë‹ˆì²˜ ì°¨ì´ë¥¼ í¡ìˆ˜í•˜ê¸° ìœ„í•œ í˜¸í™˜ ë˜í¼.
    1) build_prompt(ctx) ìš°ì„ 
    2) build_prompt(passage, difficulty)
    3) build_prompt(passage)
    (â€» generate ê²½ë¡œ í˜¸í™˜ìš©. quote ì „ìš© í›…ì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    """
    ctx = {
        "item_id": item_id,
        "difficulty": (difficulty or "medium"),
        "topic": topic,
        "passage": passage,
    }
    # 1) ctx ê¸°ë°˜
    try:
        return spec.build_prompt(ctx)
    except TypeError:
        pass
    except Exception:
        # ë‹¤ë¥¸ ì˜ˆì™¸ëŠ” ìƒìœ„ì—ì„œ ì¡íˆë„ë¡ ê·¸ëŒ€ë¡œ ì˜¬ë¦¼
        raise

    # 2) (passage, difficulty)
    try:
        return spec.build_prompt(passage, (difficulty or "medium"))
    except TypeError:
        pass
    except Exception:
        raise

    # 3) (passage)
    return spec.build_prompt(passage)

def _repair_compat(spec, raw: dict, passage: str) -> dict:
    """
    repair â†’ normalize ìˆœì„œë¡œ í˜¸ì¶œ. ì—†ëŠ” í•¨ìˆ˜ëŠ” ìŠ¤í‚µ.
    (â€» generate ê²½ë¡œ í˜¸í™˜ìš©. quote ì „ìš© í›…ì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    """
    data = raw
    rep = getattr(spec, "repair", None)
    if callable(rep):
        try:
            data = rep(raw, passage)
        except Exception:
            data = raw

    norm = getattr(spec, "normalize", None)
    if callable(norm):
        try:
            data = norm(data)
        except Exception:
            pass
    return data

def _validate_compat(spec, data: dict) -> Tuple[bool, Optional[str]]:
    """
    1) spec.model() ìˆìœ¼ë©´ validate_with_model ì‚¬ìš©
    2) spec.validate(data) ìˆìœ¼ë©´ ì˜ˆì™¸ ì—¬ë¶€ë¡œ íŒì •
    3) ë‘˜ ë‹¤ ì—†ìœ¼ë©´ True
    (â€» generate ê²½ë¡œ í˜¸í™˜ìš©. quote ì „ìš© í›…ì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    """
    model_fn = getattr(spec, "model", None)
    if callable(model_fn):
        try:
            ok, err = validate_with_model(model_fn(), data)
            return bool(ok), (str(err) if err else None)
        except Exception as e:
            return False, f"model/validation error: {e}"

    validate_fn = getattr(spec, "validate", None)
    if callable(validate_fn):
        try:
            validate_fn(data)  # Pydantic ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë“±
            return True, None
        except Exception as e:
            return False, str(e)

    return True, None

def _self_checks_compat(spec, data: dict, passage: str) -> List[str]:
    fn = getattr(spec, "self_checks", None)
    if callable(fn):
        try:
            issues = fn(data, passage)
            return issues or []
        except Exception:
            return ["self_checks raised an exception"]
    return []


# -----------------------------
# Global key coercion (Emergency/Safety Net)
# -----------------------------
def _coerce_common_keys(raw: Any, passage_text: Optional[str] = None) -> Any:
    """
    ì‘ê¸‰/ê²¸ìš©ì•ˆ(ì¬ê·€ ì ìš©):
    - ì–´ëŠ ê¹Šì´ì— ìˆë“  stimulus/question_stemì„ í‘œì¤€ ìŠ¤í™ í‚¤(passage, question)ë¡œ ë§¤í•‘í•œë‹¤.
    - ê²€ì¦ ì „(ìŠ¤í™ repair í˜¸ì¶œ ì „) í•œ ë²ˆ ì ìš©.
    """
    # dict: í‚¤ ì¹˜í™˜ + ê°’ ì¬ê·€
    if isinstance(raw, dict):
        out: Dict[str, Any] = {}
        for k, v in raw.items():
            new_k = k
            if k == "stimulus":
                new_k = "passage"
            elif k == "question_stem":
                new_k = "question"
            out[new_k] = _coerce_common_keys(v, passage_text)
        # ë°±ìŠ¤í†±: passage ëˆ„ë½ ì‹œ ìƒìœ„ì—ì„œ ë°›ì€ ì§€ë¬¸ ë³´ê°•
        if "passage" not in out and passage_text:
            out["passage"] = passage_text
        return out

    # list/tuple: ìš”ì†Œ ì¬ê·€
    if isinstance(raw, list):
        return [_coerce_common_keys(x, passage_text) for x in raw]

    # ê¸°íƒ€ ìŠ¤ì¹¼ë¼: ê·¸ëŒ€ë¡œ
    return raw


# -----------------------------
# Public API (QUOTE-ONLY PIPELINE)
# -----------------------------
def generate_multi_from_passage(
    passage: str,
    types: List[str],
    n_per_type: int = 1,
    difficulty: Optional[str] = None,
    seed: Optional[int] = None,
) -> List[Dict[str, Any]]:
    """
    ì¸ìš©(quote) ê¸°ë°˜ ìƒì„± íŒŒì´í”„ë¼ì¸.
    - generate(ìƒì„±) ê²½ë¡œì—ëŠ” ì˜í–¥ ì—†ìŒ (generate.py ë³„ë„).
    - ë¬¸í•­ ë‹¨ìœ„ë¡œ ì˜ˆì™¸ë¥¼ ë¶„ë¦¬ ì²˜ë¦¬í•˜ì—¬ ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ë¬¸í•­ì€ ì •ìƒ ë°˜í™˜.

    ë°˜í™˜ í˜•ì‹:
    [
      { "ok": True,  "item": {...}, "meta": {"type": "RC33", "seed": ..., "item_id": "RC33"} },
      { "ok": False, "message": "ì˜ëª»ëœ ìƒì„±ì…ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•´ ì£¼ì„¸ìš”",
        "error": {"detail": "...(ìµœëŒ€ 300ì)"}, "meta": {"type": "...", "seed": ..., "item_id": "..."} }
    ]
    """
    if seed is not None:
        random.seed(seed)

    results: List[Dict[str, Any]] = []
    item_prompt_keys = set(ITEM_PROMPTS.keys())
    FAIL_MSG = "ì˜ëª»ëœ ìƒì„±ì…ë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•´ ì£¼ì„¸ìš”"

    def _append_fail(t: str, item_id: str, seed_val: Optional[int], detail: Optional[str] = None) -> None:
        results.append({
            "ok": False,
            "message": FAIL_MSG,
            "error": {"detail": (detail or "")[:300]},
            "meta": {"type": t, "seed": seed_val, "item_id": item_id},
        })

    for t in types:
        # 1) type â†’ item_id í•´ì„
        try:
            item_id = resolve_item_id_from_type(t, item_prompts_keys=item_prompt_keys)
        except Exception as e:
            _append_fail(t, "UNKNOWN", seed, f"type resolve error: {e}")
            continue

        # 2) spec í™•ë³´
        spec = get_spec(item_id)
        if spec is None:
            _append_fail(t, item_id, seed, f"unknown type: {t}")
            continue

        # 3) ì „ì²˜ë¦¬/ë¦¬íƒ€ê¹ƒíŒ… (ì¸ìš© ì „ìš©, í•­ëª© ë‹¨ìœ„ ì‹¤íŒ¨ ì²˜ë¦¬)
        try:
            ctx_pre = build_ctx_for_custom(item_id, passage, difficulty, "random")
            prepped_passage = ctx_pre["passage"]
        except Exception as e:
            _append_fail(t, item_id, seed, f"preprocess error: {e}")
            continue

        # 4) n_per_type ë§Œí¼ ìƒì„±
        for _ in range(max(1, n_per_type)):
            try:
                # ============== QUOTE vs (legacy) GENERATE ë¶„ê¸° ==============
                has_quote = getattr(spec, "has_quote_support", lambda: False)()
                if has_quote:
                    # --- QUOTE ì „ìš© íë¦„ (ìŠ¤í™ í›… ì‚¬ìš©) ---
                    # 4-1) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    try:
                        prompt = spec.quote_build_prompt(prepped_passage)
                    except Exception as e:
                        _append_fail(t, item_id, seed, f"quote_build_prompt error: {e}")
                        continue

                    # 4-2) LLM í˜¸ì¶œ (ë©”íƒ€ JSONë§Œ ìˆ˜ì‹ )
                    #     quote í”„ë¡¬í”„íŠ¸ê°€ ì¶©ë¶„íˆ ê°•í•˜ë¯€ë¡œ systemì€ ìµœì†Œí•œìœ¼ë¡œ ìœ ì§€
                    raw = call_llm_json(
                        system="You are a careful JSON-only generator. Return JSON only.",
                        user=prompt,
                        temperature=0.2,
                        max_tokens=1200,
                        timeout_s=18,
                        retries=0,
                    )
                    if not raw or (isinstance(raw, dict) and raw.get("ok") is False):
                        _append_fail(t, item_id, seed, "llm returned no valid JSON (quote)")
                        continue

                    # 4-3) (ì„ íƒ) ê¸€ë¡œë²Œ í‚¤ ë³´ì • â€” passage ë³´ê°• ì™¸ì—ëŠ” ì˜í–¥ ì—†ìŒ
                    raw = _coerce_common_keys(raw, prepped_passage)

                    # 4-4) ìŠ¤í™ ì‚¬í›„ì²˜ë¦¬(ê²°ì •ë¡ ì  í‘œì‹ ì‚½ì…) + ê²€ì¦
                    try:
                        data_item = spec.quote_postprocess(prepped_passage, raw)
                    except Exception as e:
                        _append_fail(t, item_id, seed, f"quote_postprocess error: {e}")
                        continue

                    try:
                        spec.quote_validate(data_item)
                    except Exception as e:
                        _append_fail(t, item_id, seed, f"quote_validate error: {e}")
                        continue

                    # 4-5) HTML ìœ„ìƒ ì²˜ë¦¬
                    data_item = sanitize_html(data_item)

                    results.append({
                        "ok": True,
                        "item": data_item,
                        "meta": {"type": t, "seed": seed, "item_id": item_id, "mode": "quote"},
                    })
                    continue  # quote ë¶„ê¸° ì¢…ë£Œ

                # --- (Fallback) ê¸°ì¡´ í˜¸í™˜ íë¦„ (ì¼ë¶€ ìŠ¤í™ì´ quote í›… ì—†ì„ ë•Œ) ---
                prompt = _build_prompt_compat(
                    spec, prepped_passage, item_id=item_id, difficulty=difficulty, topic="random"
                )
                # ì§€ë¬¸ ì‚½ì…ì´ ëˆ„ë½ë˜ì–´ ìˆìœ¼ë©´ ë³´ê°•
                if (
                    prepped_passage and prepped_passage.strip()
                    and ("```passage" not in prompt) and ("<PASSAGE>" not in prompt)
                ):
                    prompt = make_prompt_with_passage(prompt, prepped_passage.strip())

                # ì„¸íŠ¸í˜•(ì¥ë¬¸ ì„¸íŠ¸) ë¶„ê¸°: RC41/RC42/RC41_42 ëŠ” ë” íƒ€ì´íŠ¸í•œ ì˜ˆì‚° ì‚¬ìš©
                is_set_type = item_id in ("RC41", "RC42", "RC41_42")

                # ì‘ë‹µ ì§€ì—°ì„ ì¤„ì´ê¸° ìœ„í•œ ì˜ˆì‚° ì¡°ì •
                llm_max_tokens = 1000 if is_set_type else 1500
                llm_timeout_s  = 16  if is_set_type else 18

                raw = call_llm_json(
                    system=_get_system_prompt(spec, prepped_passage),
                    user=prompt,
                    temperature=0.2,
                    max_tokens=llm_max_tokens,
                    timeout_s=llm_timeout_s,
                    retries=0,                 # ğŸŸ¢ ì¬ì‹œë„ ë”: ë¬¸í•­ ë‹¨ìœ„ë¡œ ë¹¨ë¦¬ ì‹¤íŒ¨-ìˆ˜ê±°
                )

                # ìœ íš¨ì„± 1ì°¨ í™•ì¸
                if not raw or (isinstance(raw, dict) and raw.get("ok") is False):
                    _append_fail(t, item_id, seed, "llm returned no valid JSON")
                    continue

                # âœ… ì‘ê¸‰/ê²¸ìš©ì•ˆ: ê¸€ë¡œë²Œ í‚¤ ë³´ì • (stimulus/question_stem â†’ passage/question), ì¬ê·€ ì ìš©
                raw = _coerce_common_keys(raw, prepped_passage)

                # repair/normalize (ìŠ¤í™ë³„ ë³´ì •)
                data = _repair_compat(spec, raw, prepped_passage)

                # validate (ëª¨ë¸/í•¨ìˆ˜)
                ok, err = _validate_compat(spec, data)
                if not ok:
                    # ë§ˆì§€ë§‰ ë³´ì • ì‹œë„
                    data = _repair_compat(spec, data, prepped_passage)
                    ok, err = _validate_compat(spec, data)

                if ok:
                    data = sanitize_html(data)

                # self checks
                issues = _self_checks_compat(spec, data, prepped_passage)

                if ok and not issues:
                    results.append({
                        "ok": True,
                        "item": data,
                        "meta": {"type": t, "seed": seed, "item_id": item_id, "mode": "compat"},
                    })
                else:
                    detail = f"validation: {err}; issues: {issues}"
                    _append_fail(t, item_id, seed, detail)

            except (json.JSONDecodeError, ValueError) as e:
                # LLM JSON íŒŒì‹±/ìŠ¤í‚¤ë§ˆë¥˜ ì‹¤íŒ¨ â†’ í•´ë‹¹ ë¬¸í•­ë§Œ ì‹¤íŒ¨
                _append_fail(t, item_id, seed, f"json/validation error: {e}")
                continue
            except Exception as e:
                # ê·¸ ì™¸ ëª¨ë“  ì˜ˆì™¸ë„ í•´ë‹¹ ë¬¸í•­ë§Œ ì‹¤íŒ¨
                _append_fail(t, item_id, seed, f"unhandled: {e}")
                continue

    return results
