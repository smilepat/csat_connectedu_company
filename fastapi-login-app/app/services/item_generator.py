# app/services/item_generator.py
import asyncio
import json
import logging
import re
import time
from typing import Any
from pydantic import ValidationError
import inspect

from fastapi import HTTPException  # (í˜„ì¬ëŠ” ì‚¬ìš© ì•ˆ í•˜ì§€ë§Œ, ì™¸ë¶€ì—ì„œ ì°¸ì¡°í•  ìˆ˜ ìˆì–´ ë‚¨ê²¨ë‘ )

from app.core import openai_config
from app.core.settings import settings
from app.prompts.prompt_manager import PromptManager
from app.prompts.prompt_data import ITEM_PROMPTS

# ë ˆê±°ì‹œ(MCQ) í´ë°±ìš© ìŠ¤í‚¤ë§ˆ
from app.schemas.items_mcq import MCQItem

# Spec ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
from app.specs.registry import get_spec
from app.specs.utils import strip_code_fence

logger = logging.getLogger("service.item_generator")

# last_schema_errors = None

# =========================
# JSON/Parsing Utilities
# =========================

def pre_json_fix(text: str) -> str:
    """
    ëª¨ë¸ ì¶œë ¥ì—ì„œ ì½”ë“œíœìŠ¤/ìŠ¤ë§ˆíŠ¸ì¿¼íŠ¸/ì •ë‹µê¸°í˜¸ ë“± ìì£¼ ì–´ê¸‹ë‚˜ëŠ” í¬ë§·ì„ 1ì°¨ êµì •.
    """
    s = (text or "").strip()
    s = re.sub(r"```(?:json)?\s*([\s\S]*?)```", r"\1", s, flags=re.IGNORECASE)
    s = s.replace("â€œ", '"').replace("â€", '"').replace("â€˜", "'").replace("â€™", "'")
    # ì •ë‹µ ê¸°í˜¸ê°€ â‘ ~â‘¤ì¸ë° ë”°ì˜´í‘œê°€ ëˆ„ë½ëœ ê²½ìš°ë¥¼ ë°©ì–´
    s = re.sub(r'("correct_answer"\s*:\s*)([â‘ â‘¡â‘¢â‘£â‘¤])', r'\1"\2"', s)
    return s.strip()


def _json_schema_of(model_cls) -> dict:
    """
    Pydantic v2 / v1 í˜¸í™˜ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
    """
    try:
        return model_cls.model_json_schema()  # v2
    except Exception:
        return model_cls.schema()             # v1


def _parse_json_loose(s: str) -> dict:
    """
    JSON ë³¸ë¬¸ ì•ë’¤ì— ì¡ì†Œë¦¬ê°€ ì„ì¸ ê²½ìš°, ë§ˆì§€ë§‰ ë‹«ëŠ” ê´„í˜¸ê¹Œì§€ë¥¼ ì°¾ì•„ íŒŒì‹±.
    - âœ… ë¹ˆ ì‘ë‹µ / ë‹«ëŠ” ê´„í˜¸ ì—†ìŒ ì¼€ì´ìŠ¤ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ ì˜ˆì™¸ ë©”ì‹œì§€ ë¶€ì—¬
    """
    s = (s or "").strip()  # âœ…
    if not s:
        # ë¹ˆ ë¬¸ìì—´ì€ ìƒìœ„ì—ì„œ ì¦‰ì‹œ ì¬ìƒì„± ë£¨í”„ë¡œ ê°€ë„ë¡ ëª…í™•í•œ ì˜ˆì™¸ ë¶€ì—¬
        raise json.JSONDecodeError("empty_response", "", 0)  # âœ…
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        m = re.search(r'\{[\s\S]*\}\s*$', s)
        if not m:
            # ë‹«ëŠ” ê´„í˜¸ ìì²´ê°€ ì—†ìœ¼ë©´ ìƒìœ„ì—ì„œ ì¬ìƒì„±
            raise json.JSONDecodeError("no_closing_brace_found", s[:80], 0)  # âœ…
        return json.loads(m.group(0))


def _validate_mcq(data: dict) -> MCQItem:
    """
    ë ˆê±°ì‹œ MCQ ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì‹¤íŒ¨ ì‹œ ValidationError)
    """
    return MCQItem(**data)


def _ensure_plain_dict(obj: Any) -> dict:
    """
    Pydantic BaseModel ë˜ëŠ” ê¸°íƒ€ ê°ì²´ë¥¼ í•­ìƒ plain dictë¡œ ë³€í™˜.
    """
    if isinstance(obj, dict):
        return obj
    if hasattr(obj, "model_dump"):
        try:
            return obj.model_dump()
        except Exception:
            pass
    if hasattr(obj, "dict"):
        try:
            return obj.dict()
        except Exception:
            pass
    return obj  # dictê°€ ì•„ë‹ ìˆ˜ë„ ìˆìœ¼ë‚˜, í˜¸ì¶œë¶€ì—ì„œ ë‹¤ì‹œ ë³´ì •


def _is_blank(s: Any) -> bool:
    """âœ… ë¬¸ìì—´ì´ ë¹„ì–´ìˆê±°ë‚˜ ê³µë°±ë¿ì¸ì§€ í™•ì¸."""
    return (not isinstance(s, str)) or (not s.strip())


# =========================
# Model Call Wrapper
# =========================

async def _call_chat(messages: list[dict[str, str]], trace_id: str | None, timeout_s: float) -> str:
    """
    openai_config.chat_completion ì„ sync/async ëª¨ë‘ í˜¸í™˜í•˜ê²Œ í˜¸ì¶œ.
    """
    try:
        maybe = openai_config.chat_completion(messages=messages, trace_id=trace_id, timeout_s=timeout_s)
    except TypeError:
        # êµ¬ë²„ì „ ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜
        maybe = openai_config.chat_completion(messages)

    if asyncio.iscoroutine(maybe):
        return await asyncio.wait_for(maybe, timeout=timeout_s)

    loop = asyncio.get_running_loop()
    return await asyncio.wait_for(loop.run_in_executor(None, lambda: maybe), timeout=timeout_s)


# =========================
# Safe Validator Wrapper
# =========================

async def _spec_validate_safe(spec_obj, data, *, content_only_flag: bool):
    """
    ìŠ¤í™ì˜ validate í˜¸ì¶œì„ ì•ˆì „í•˜ê²Œ ê°ì‹¼ë‹¤.
    - ìŠ¤í™ì´ content_only íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ë©´ ì „ë‹¬
    - ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ì „ë‹¬í•˜ì§€ ì•Šê³  í˜¸ì¶œ
    - sync/async ëª¨ë‘ ì²˜ë¦¬
    """
    fn = getattr(spec_obj, "validate", None)
    if fn is None:
        return

    # íŒŒë¼ë¯¸í„° ìˆ˜ìš© ì—¬ë¶€ í™•ì¸
    try:
        sig = inspect.signature(fn)
        accepts_content_only = "content_only" in sig.parameters
    except Exception:
        accepts_content_only = False

    kwargs = {"content_only": content_only_flag} if accepts_content_only else {}

    if inspect.iscoroutinefunction(fn):
        return await fn(data, **kwargs)
    else:
        return fn(data, **kwargs)


# =========================
# Repair Helpers (schema_dict ë²„ì „)
# =========================

async def _fix_with_schema(raw: str, schema_dict: dict, trace_id: str | None, timeout_s: float) -> str:
    """
    Fixer: ì„ì˜ í…ìŠ¤íŠ¸(raw)ë¥¼ ì£¼ì–´ì§„ JSON ìŠ¤í‚¤ë§ˆì— 'ë§ëŠ”' VALID JSONìœ¼ë¡œ ë³€í™˜ë§Œ ìˆ˜í–‰.
    ì¶œë ¥ì€ ë°˜ë“œì‹œ ìˆœìˆ˜ JSON (ì½”ë“œíœìŠ¤/ì„¤ëª… ì—†ìŒ).
    """
    schema = json.dumps(schema_dict, ensure_ascii=False)
    messages = [
        {
            "role": "system",
            "content": (
                "You convert the user's text into VALID JSON strictly matching the provided JSON Schema. "
                "Output ONLY the JSON. No code fences, no prose."
            ),
        },
        {
            "role": "user",
            "content": f"JSON Schema:\n{schema}\n\nInput:\n{raw}",
        },
    ]
    return await _call_chat(messages, trace_id, timeout_s)


async def _regenerate_strict(prompt_str: str, schema_dict: dict, trace_id: str | None, timeout_s: float) -> str:
    """
    Strict Regeneration: ìŠ¤í‚¤ë§ˆë¥¼ ê°•ì œí•˜ë©´ì„œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ìƒì„±.
    ì¶œë ¥ì€ ë°˜ë“œì‹œ ìˆœìˆ˜ JSON.
    """
    schema = json.dumps(schema_dict, ensure_ascii=False)
    messages = [
        {
            "role": "system",
            "content": (
                "CSAT English item generator. Return ONLY JSON strictly matching the provided JSON Schema. "
                "No code fences. No explanations. Korean content is allowed."
            ),
        },
        {
            "role": "user",
            "content": f"JSON Schema:\n{schema}\n\nNow generate according to this instruction:\n{prompt_str}",
        },
    ]
    return await _call_chat(messages, trace_id, timeout_s)


# =========================
# Public API
# =========================

async def generate_item(item_id: str, payload: Any, *, trace_id: str | None = None) -> dict:
    """
    Spec ê¸°ë°˜ íŒŒì´í”„ë¼ì¸:
      1) specì´ ìˆìœ¼ë©´ spec.normalize/validate/json_schema/repair_budget ì‚¬ìš©
      2) ì—†ìœ¼ë©´ ë ˆê±°ì‹œ(MCQItem) ê²½ë¡œë¡œ í´ë°±
      3) í•­ìƒ Envelope ì‘ë‹µ í˜•íƒœ ë°˜í™˜:
         - ì„±ê³µ: {"ok": True, "item": <dict>, "meta": {...}}
         - ì‹¤íŒ¨: {"ok": False, "error": {...}, "meta": {...}}
    """
    logger.info("item_generator LOADED v2025-10-15-L2")
    # ---------- ì…ë ¥ ì»¨í…ìŠ¤íŠ¸ ----------
    schema_errors = None

    difficulty = getattr(payload, "difficulty", None) or (payload.get("difficulty") if isinstance(payload, dict) else None)
    topic = getattr(payload, "topic", None) or (payload.get("topic") if isinstance(payload, dict) else None)
    passage_text = getattr(payload, "passage", None) or (payload.get("passage") if isinstance(payload, dict) else None)
    passage_text = (passage_text or "").strip()

    # (SIMPLE) vocab_profileì€ í•­ìƒ í”„ë¡¬í”„íŠ¸ì— ìˆë‹¤ê³  ê°€ì •í•˜ê³  ê±°ê¸°ì„œë§Œ ì¶”ì¶œ
    def _vocab_from_prompt(_item_id: str) -> str:
        content = ITEM_PROMPTS.get(_item_id, {}).get("content", "") or ""
        m = re.search(r'"vocabulary_difficulty"\s*:\s*"([^"]+)"', content)
        if not m:
            # í”„ë¡¬í”„íŠ¸ì— ë°˜ë“œì‹œ ìˆë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ, ì—†ìœ¼ë©´ ëª…í™•íˆ ì‹¤íŒ¨ì‹œì¼œ ì›ì¸ ë…¸ì¶œ
            raise ValueError(f'vocabulary_difficulty not found in prompt content for item_id={_item_id}')
        return m.group(1).strip()

    vocab_profile = _vocab_from_prompt(item_id)

    # enable_overlayëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€
    enable_overlay = getattr(payload, "enable_overlay", None) if not isinstance(payload, dict) else payload.get("enable_overlay")
    if enable_overlay is None:
        enable_overlay = getattr(settings, "USE_PROMPT_OVERLAY", True)

    t0 = time.perf_counter()
    meta_base = {
        "trace_id": trace_id, "item_id": item_id,
        "difficulty": difficulty, "topic": topic,
        "has_passage": bool(passage_text), "passage_len": len(passage_text),
        "vocab_profile": vocab_profile, "enable_overlay": enable_overlay,
    }
    logger.info("generate_start", extra=meta_base)

    # âœ… ê³µí†µ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì„ í–‰ ìƒì„±: content-first/ê³µìš© ê²½ë¡œ/í”„ë¡¬í”„íŠ¸ ë¹Œë“œì—ì„œ ì¼ê´€ ì‚¬ìš©
    ctx = {
        "item_id": item_id,
        "difficulty": difficulty or "medium",
        "topic": topic or "random",
        "passage": passage_text or "",
        "vocab_profile": vocab_profile,
        "enable_overlay": bool(enable_overlay),
    }
    

    # ---------- Spec ì¡°íšŒ ----------
    spec = get_spec(item_id)
    is_rc25 = (item_id == "RC25")

    # Helper: sync/async í•¨ìˆ˜ ëª¨ë‘ ì•ˆì „ í˜¸ì¶œ
    async def _maybe_call(fn, *args, **kwargs):
        if inspect.iscoroutinefunction(fn):
            return await fn(*args, **kwargs)
        return fn(*args, **kwargs)

    # - ì´ë¯¸ passageê°€ ìˆì„ ë•Œë§Œ spec.build_promptë¥¼ ì‚¬ìš©
    # - ê·¸ ì™¸(ì¼ë°˜ ìƒì„±)ëŠ” í•­ìƒ PromptManager.generate ì‚¬ìš©
    # - build_promptê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìœ¼ë©´ ì¦‰ì‹œ PM ê²½ë¡œë¡œ í´ë°±
    try:
        if spec and passage_text and hasattr(spec, "build_prompt"):
            print("ì¸ìš©", item_id)
            prompt_str = await _maybe_call(spec.build_prompt, ctx)
            # build_promptê°€ ë¹„ì–´ìˆìœ¼ë©´ PM ê²½ë¡œë¡œ í´ë°±
            if not isinstance(prompt_str, str) or not prompt_str.strip():
                logger.warning("prompt_not_available", extra={**meta_base})
                print("ìƒì„±(í´ë°±)", item_id)
                prompt_str = PromptManager.generate(
                    item_type=item_id,
                    difficulty=ctx["difficulty"],
                    topic_code=ctx["topic"],
                    passage=ctx["passage"],
                    vocab_profile=ctx["vocab_profile"],
                    enable_overlay=ctx["enable_overlay"],
                )
        else:
            print("ìƒì„±", item_id)
            prompt_str = PromptManager.generate(
                item_type=item_id,
                difficulty=ctx["difficulty"],
                topic_code=ctx["topic"],
                passage=ctx["passage"],
                vocab_profile=ctx["vocab_profile"],
                enable_overlay=ctx["enable_overlay"],
            )
    except Exception as e:
        logger.exception("prompt_build_failed", extra=meta_base)
        return {
            "ok": False,
            "error": {"type": "PromptError", "message": str(e)},
            "meta": {**meta_base, "phase": "prompt_build"},
        }

    if isinstance(prompt_str, str):
        logger.info("prompt_ready", extra={**meta_base, "prompt_len": len(prompt_str)})
    else:
        logger.warning("prompt_not_available", extra={**meta_base})

    # íƒ€ì„ì•„ì›ƒ/ë¦¬í˜ì–´ ì˜ˆì‚°
    timeout_s = max(1.0, settings.REQUEST_TIMEOUT_MS / 1000)
    fixer_allowed = True
    regen_rounds = 1

    if spec:
        budget = spec.repair_budget() or {}
        timeout_s = budget.get("timeout_s", timeout_s)
        fixer_allowed = budget.get("fixer", 1) > 0
        regen_rounds = budget.get("regen", 1)

    # ğŸ”¹ RC25 ì „ìš©: Fixer ë¹„í™œì„±í™”(ë‚´ìš©ì˜¤ë¥˜ì— ë¹„íš¨ìœ¨) + Regenerate ìš°ì„ 
    if is_rc25:
        fixer_allowed = False
        regen_rounds = max(regen_rounds, 2)

    # ---------- ê²€ì¦ ë˜í¼ ----------
    async def _validate_any(text: str, spec_obj, has_spec: bool) -> tuple[dict, str]:
        cleaned_local = strip_code_fence(pre_json_fix(text))
        print("ğŸ” [item_generator] raw model output =", text[:400])
        print("ğŸ” [item_generator] cleaned =", cleaned_local[:400])
        data_local = _parse_json_loose(cleaned_local)

        if has_spec:
            data_local = spec_obj.normalize(data_local)
            # ğŸ”¹ RC25: ë¨¼ì € ë¹ ë¥¸ ì˜ˆë¹„ê²€ì‚¬(fast_precheck)ë¡œ ì €ë ´í•˜ê²Œ íƒˆë½ì‹œí‚¨ ë’¤,
            #          ë³¸ ê²€ì¦ì€ í˜¸ì¶œë¶€(ì„±ê³µ ê²½ë¡œ)ì—ì„œ ì—„ê²©ëª¨ë“œë¡œ ìˆ˜í–‰
            if is_rc25 and hasattr(spec_obj, "fast_precheck"):
                ok_fast, reason = spec_obj.fast_precheck(data_local)
                if not ok_fast:
                    # ì˜ˆë¹„ê²€ì‚¬ ì¦‰ì‹œ ì‹¤íŒ¨ â†’ Fixer ìƒëµ, ì¬ìƒì„± ë‹¨ê³„ë¡œ ì´ë™
                    raise ValueError(f"fast_precheck_failed:{reason}")
            elif not is_rc25:
                # ë¹„ RC25 ë¬¸í•­ì€ ì¢…ì „ ë¡œì§ ìœ ì§€
                await _spec_validate_safe(spec_obj, data_local, content_only_flag=False)
        else:
            _validate_mcq(data_local)

        return data_local, cleaned_local

    phase = "primary"
    attempts = 0

    # ---------- 1) 1ì°¨ ìƒì„± ----------
    # RC25 ì „ìš©: ìŠ¤í™ ë‚´ë¶€ content-first ë£¨í”„ë¥¼ í˜¸ì¶œí•´ ìƒì„±/ê²€ì¦ì„ ëë‚¸ë‹¤.
    if spec and is_rc25 and hasattr(spec, "content_first_generate"):
        phase = "primary"
        attempts = 1
        try:
            data = await spec.content_first_generate(ctx)   # âœ… ìŠ¤í™ ë‚´ë¶€ ë£¨í”„ í™œìš©
            # âœ… ê·œì¹™ ê°•ì œ: ì—¬ê¸°ì„œë„ ì—„ê²© ê²€ì¦(content_only=False)ìœ¼ë¡œ í™•ì •
            #   - ê±°ì§“ ê°œìˆ˜ â‰  1 â†’ ì˜ˆì™¸ â†’ ì•„ë˜ exceptì—ì„œ ê³µìš© ê²½ë¡œ í´ë°± â†’ Regenerate
            #   - ê±°ì§“ 1ê°œ & ì •ë‹µ ë¶ˆì¼ì¹˜ â†’ auto-fix(ì •ë‹µ/í•´ì„¤ ë³´ì •)
            await _spec_validate_safe(spec, data, content_only_flag=False)
            dt = int((time.perf_counter() - t0) * 1000)
            logger.info("generate_success_primary", extra={**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt})
            return {"ok": True, "item": _ensure_plain_dict(data), "meta": {**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt}}
        except Exception as e:
            # â— content-first ì‹¤íŒ¨ ì‹œ: ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜í•˜ì§€ ë§ê³  ê³µìš© ê²½ë¡œë¡œ í´ë°±
            logger.warning("rc25_content_first_failed_fallback_to_common", extra={**meta_base, "error": str(e)})

    # ---------- 1) 1ì°¨ ìƒì„± (ê³µìš© ê²½ë¡œ) ----------
    try:
        attempts += 1
        system_msg = "CSAT English item generator"
        if passage_text:
            system_msg += " â€” Use ONLY the provided passage. Do NOT invent or substitute a new passage."

        raw = await _call_chat(
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt_str},
            ],
            trace_id=trace_id,
            timeout_s=timeout_s,
        )
        # âœ… ë¹ˆ ì‘ë‹µ 1íšŒ ì¬ì‹œë„ (ì¼ì‹œì  í•„í„°/ë„¤íŠ¸ì›Œí¬/ì„œë²„ìƒíƒœ)
        if _is_blank(raw):
            logger.warning("empty_model_response_primary_retry", extra={**meta_base})  # âœ…
            raw = await _call_chat(
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt_str},
                ],
                trace_id=trace_id,
                timeout_s=timeout_s,
            )
            if _is_blank(raw):
                raise ValueError("empty_model_response_primary")  # âœ…

        data, cleaned = await _validate_any(raw, spec, has_spec=bool(spec))
        # ğŸ”¹ RC25ëŠ” ì˜ˆë¹„ê²€ì‚¬ í†µê³¼ í›„ ì—¬ê¸°ì„œ â€˜ì—„ê²© ê²€ì¦(content_only=False)â€™ ìˆ˜í–‰
        if spec and is_rc25:
            await _spec_validate_safe(spec, data, content_only_flag=False)
        dt = int((time.perf_counter() - t0) * 1000)
        logger.info("generate_success_primary", extra={**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt})
        return {"ok": True, "item": data, "meta": {**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt}}

    except ValidationError as ve:
        # âœ… pydantic v1/v2 ëª¨ë‘ í˜¸í™˜
        try:
            schema_errors = ve.errors()
        except Exception:
            schema_errors = str(ve)
        logger.warning("validation_failed", extra={**meta_base, "errors": schema_errors})
    except Exception as e1:
        logger.warning("primary_failed", extra={**meta_base, "error": str(e1)})

    # ---------- 2) Fixer ----------
    if fixer_allowed:
        try:
            attempts += 1
            schema_dict = spec.json_schema() if spec else _json_schema_of(MCQItem)
            fixed = await _fix_with_schema(
                raw if "raw" in locals() else "",
                schema_dict=schema_dict,
                trace_id=trace_id,
                timeout_s=timeout_s,
            )
            # âœ… Fixer ê²°ê³¼ ë¹ˆ ì‘ë‹µ ë°©ì–´
            if _is_blank(fixed):
                raise ValueError("empty_fixer_response")  # âœ…

            data = _parse_json_loose(pre_json_fix(fixed))
            if spec:
                data = spec.normalize(data)
                await _spec_validate_safe(spec, data, content_only_flag=False)
            else:
                _validate_mcq(data)

            phase = "fixed"
            dt = int((time.perf_counter() - t0) * 1000)
            logger.info("generate_success_fixed", extra={**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt})
            return {"ok": True, "item": data, "meta": {**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt}}
        except ValidationError as ve2:
            try:
                schema_errors = ve2.errors()
            except Exception:
                schema_errors = str(ve2)
            logger.warning("fixer_validation_failed", extra={**meta_base, "errors": schema_errors})
        except Exception as e2:
            logger.warning("fixer_failed", extra={**meta_base, "error": str(e2)})

    # ---------- 3) Regenerate (NíšŒ) ----------
    for i in range(max(1, regen_rounds)):
        try:
            attempts += 1
            schema_dict = spec.json_schema() if spec else _json_schema_of(MCQItem)
            regen = await _regenerate_strict(
                prompt_str,
                schema_dict=schema_dict,
                trace_id=trace_id,
                timeout_s=timeout_s,
            )
            # âœ… ë¦¬ì   ê²°ê³¼ ë¹ˆ ì‘ë‹µì´ë©´ ì¦‰ì‹œ ë‹¤ìŒ ë¼ìš´ë“œë¡œ
            if _is_blank(regen):
                logger.warning("empty_model_response_regen", extra={**meta_base, "round": i + 1})  # âœ…
                raise ValueError("empty_model_response_regen")  # âœ… -> exceptì—ì„œ ì¡íˆê³  ë‹¤ìŒ ë¼ìš´ë“œ ì§„í–‰

            data = _parse_json_loose(pre_json_fix(regen))
            if spec:
                data = spec.normalize(data)
                await _spec_validate_safe(spec, data, content_only_flag=False)
            else:
                _validate_mcq(data)

            phase = f"regenerated_{i+1}"
            dt = int((time.perf_counter() - t0) * 1000)
            logger.info("generate_success_regenerated", extra={**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt})
            return {"ok": True, "item": data, "meta": {**meta_base, "phase": phase, "attempts": attempts, "duration_ms": dt}}
        except ValidationError as ve3:
            try:
                schema_errors = ve3.errors()
            except Exception:
                schema_errors = str(ve3)
        except Exception as e3:
            logger.warning("regenerate_failed", extra={**meta_base, "round": i + 1, "error": str(e3)})

    # ---------- 4) ìµœì¢… ì‹¤íŒ¨ ----------
    snippet = (locals().get("cleaned") if "cleaned" in locals() else (locals().get("raw") or ""))[:1000]
    dt = int((time.perf_counter() - t0) * 1000)
    logger.error(
        "generate_failed_final",
        extra={**meta_base, "attempts": attempts, "duration_ms": dt}
    )
    return {
        "ok": False,
        "error": {
            "type": "InvalidModelOutput",
            "message": "Model output invalid after repair/regeneration",
            "snippet": snippet,
            "schema_errors": schema_errors,  # âœ… ë¡œì»¬ ë³€ìˆ˜ ì‚¬ìš©
        },
        "meta": {**meta_base, "attempts": attempts, "duration_ms": dt},
    }
