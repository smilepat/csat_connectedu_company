# app/specs/rc21_underlined_inference.py
from __future__ import annotations
from typing import Any
import re

from pydantic import BaseModel, Field, field_validator, model_validator, ConfigDict

from app.specs.base import ItemSpec, GenContext
from app.prompts.prompt_manager import PromptManager
from app.specs.utils import coerce_mcq_like  # âœ… í‘œì¤€í™”(ë¼ë²¨â†’ìˆ«ì ë¬¸ìì—´ ë“±) 1ì°¨ ì²˜ë¦¬


class RC21Model(BaseModel):
    """
    RC21: í•¨ì˜/ì¶”ë¡ (Inference) â€” 5ì§€ì„ ë‹¤ MCQ
    """
    question: str
    passage: str
    options: list[str] = Field(min_items=5, max_items=5)
    correct_answer: Any
    explanation: str

    # ğŸ”¹ ì¶”ê°€: ì–´íœ˜ ì •ë³´ í•„ë“œ (ì„ íƒì )
    vocabulary_difficulty: str | None = None
    low_frequency_words: list[str] | None = None

    # v2: Config â†’ model_config
    # ğŸ”¹ extraëŠ” ì´ì œ forbid ë§ê³  ignore ë¡œ ë‘ëŠ” ê±¸ ê¶Œì¥ (ì•ìœ¼ë¡œ í•„ë“œ ëŠ˜ë ¤ë„ ì•ˆ í„°ì§€ê²Œ)
    model_config = ConfigDict(extra="ignore")

    @field_validator("question", "passage", "explanation", mode="before")
    @classmethod
    def _strip(cls, v):
        return (v or "").strip()

    @field_validator("correct_answer", mode="before")
    @classmethod
    def _coerce_numeric_like(cls, v):
        """
        - intë©´ ê·¸ëŒ€ë¡œ
        - "1"~"5" ê°™ì€ ìˆ«ì ë¬¸ìì—´ì´ë©´ intë¡œ ë³€í™˜
        - ê·¸ ì™¸(ë³´ê¸° í…ìŠ¤íŠ¸ ê°€ëŠ¥)ëŠ” model_validatorì—ì„œ ì²˜ë¦¬
        """
        if isinstance(v, int):
            return v
        if isinstance(v, str) and v.isdigit():
            return int(v)
        return v

    # v2: @root_validator â†’ @model_validator(mode="after")
    @model_validator(mode="after")
    def _finalize_answer(self):
        opts = list(self.options or [])
        ca = self.correct_answer

        # ë³´ê¸° í…ìŠ¤íŠ¸ë¡œ ì˜¨ ê²½ìš° â†’ ì¸ë±ìŠ¤(1-based)ë¡œ ë³€í™˜
        if not isinstance(ca, int):
            if isinstance(ca, str):
                try:
                    idx = opts.index(ca) + 1
                    ca = idx
                except ValueError:
                    raise ValueError(
                        "correct_answer must be numeric (1-5) or match one of the options exactly"
                    )
            else:
                raise ValueError(
                    "correct_answer must be an integer 1-5 or a numeric string '1'-'5'"
                )

        # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
        if not (1 <= int(ca) <= 5):
            raise ValueError("correct_answer must be in the range 1..5")

        # ê°„ë‹¨í•œ ì˜µì…˜ í¬ë§· ìˆ˜ìœ„ ê²€ì¦(ë²ˆí˜¸Â·ê¸°í˜¸ ì ‘ë‘ ê¸ˆì§€)
        bad_prefix = re.compile(r"^\s*(?:\(?\d+\)?[.)]|[â‘ -â‘¤A-Ea-e])\s+")
        for o in opts:
            if bad_prefix.match(o or ""):
                raise ValueError("options_plain_text_only_violation")

        # v2ì—ì„œëŠ” selfë¥¼ ê°±ì‹ í•˜ë ¤ë©´ copy(update=...)ë¡œ ë°˜í™˜
        return self.model_copy(update={"correct_answer": int(ca)})


class RC21Spec(ItemSpec):
    """
    RC21 ì „ìš© ìŠ¤í™: PromptManager.generate í˜¸ì¶œ.
    passageëŠ” ìŠ¤í™ì—ì„œ ì§ì ‘ ì£¼ì….
    """
    id = "RC21"

    def system_prompt(self) -> str:
        return (
            "CSAT English RC21 (Inference). "
            "Return ONLY JSON matching the schema. "
            "Use ONLY the provided passage. Do NOT invent or substitute a new passage."
        )

    def build_prompt(self, ctx: GenContext) -> str:
        return PromptManager.generate(
            item_type=self.id,
            difficulty=(ctx.get("difficulty") or "medium"),
            topic_code=(ctx.get("topic") or "random"),
            passage=(ctx.get("passage") or ""),
        )

    # ---------- í’ˆì§ˆ ë³´ì •/ê²€ì¦ ----------
    def normalize(self, data: dict) -> dict:
        """
        1) coerce_mcq_like: í•„ë“œëª… í‘œì¤€í™” + ë¼ë²¨í˜• ì •ë‹µ(â‘ /A ë“±) â†’ "1"~"5" ì •ê·œí™”
        2) correct_answerê°€ ë³´ê¸° í…ìŠ¤íŠ¸ë©´ â†’ 1-based ì¸ë±ìŠ¤ë¡œ ì¹˜í™˜
        3) "1"~"5" ë¬¸ìì—´ì€ intë¡œ ë³€í™˜
        4) ì§ˆë¬¸ì— ìˆëŠ” <u>...</u> ëŒ€ìƒ í‘œí˜„ì„ passageì—ë„ ë°˜ë“œì‹œ ë°‘ì¤„ë¡œ ì‹±í¬
        """
        x = coerce_mcq_like(data)  # question/options/correct_answer 1ì°¨ ì •ê·œí™”

        # ë³´ê¸° í…ìŠ¤íŠ¸ â†’ ì¸ë±ìŠ¤
        ca = x.get("correct_answer")
        opts = x.get("options") or []
        if isinstance(ca, str) and not ca.isdigit() and opts:
            if ca in opts:
                x["correct_answer"] = opts.index(ca) + 1

        # ìˆ«ì ë¬¸ìì—´ â†’ int
        ca2 = x.get("correct_answer")
        if isinstance(ca2, str) and ca2.isdigit():
            x["correct_answer"] = int(ca2)

        # â”€â”€ â˜… ì§ˆë¬¸ì˜ <u>...</u>ë¥¼ passageì—ë„ ë°˜ì˜ â”€â”€
        q = x.get("question") or ""
        p = x.get("passage") or ""

        m = re.search(r"<u>(.*?)</u>", q)
        if m:
            target = (m.group(1) or "").strip()
            # ì´ë¯¸ passageì— <u>ê°€ ìˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šê³ ,
            # ì•„ì§ ë°‘ì¤„ì´ ì—†ê³ , target í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆì„ ë•Œë§Œ ì²« 1íšŒ ì¹˜í™˜.
            if target and "<u" not in p and target in p:
                x["passage"] = p.replace(target, f"<u>{target}</u>", 1)

        # ë¶ˆí•„ìš” í•„ë“œ ì œê±°
        x.pop("rationale", None)
        # ë‹¨ì–´ ì •ë³´ ì•ˆ ì“´ë‹¤ë©´ ì—¬ê¸°ì„œ ê°™ì´ ì œê±°í•´ë„ ë¨:
        # x.pop("vocabulary_difficulty", None)
        # x.pop("low_frequency_words", None)

        return x

    def validate(self, data: dict):
        RC21Model(**data)

    def json_schema(self) -> dict:
        return RC21Model.model_json_schema()

    def repair_budget(self) -> dict:
        return {"fixer": 1, "regen": 1, "timeout_s": 15}
